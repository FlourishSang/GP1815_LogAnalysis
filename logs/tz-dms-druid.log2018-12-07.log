[druid] 2018-12-07 00:38:58,040 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 00:38:58,045 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 00:38:59,271 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 00:38:59,420 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 00:38:59,501 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 00:38:59,616 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local2136411292_0001
   [druid] 2018-12-07 00:38:59,820 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 00:38:59,822 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local2136411292_0001
   [druid] 2018-12-07 00:38:59,823 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 00:38:59,834 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 00:38:59,834 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 00:38:59,842 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 00:38:59,892 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 00:38:59,896 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2136411292_0001_m_000000_0
   [druid] 2018-12-07 00:38:59,934 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 00:38:59,940 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 00:39:00,162 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@11b3f5f4
   [druid] 2018-12-07 00:39:00,173 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 00:39:00,259 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 00:39:00,259 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 00:39:00,259 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 00:39:00,259 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 00:39:00,259 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 00:39:00,264 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 00:39:00,824 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local2136411292_0001 running in uber mode : false
   [druid] 2018-12-07 00:39:00,828 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 00:39:01,543 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 00:39:01,544 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 00:39:01,545 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 00:39:01,545 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 00:39:01,546 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 00:39:01,547 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 00:39:01,548 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 00:39:01,549 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 00:39:01,549 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 00:39:05,951 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 00:39:06,835 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 9% reduce 0%
   [druid] 2018-12-07 00:39:08,953 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 00:39:09,836 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 18% reduce 0%
   [druid] 2018-12-07 00:39:11,954 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 00:39:12,837 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 26% reduce 0%
   [druid] 2018-12-07 00:39:14,955 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 00:39:15,839 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 34% reduce 0%
   [druid] 2018-12-07 00:39:17,956 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 00:39:18,840 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 42% reduce 0%
   [druid] 2018-12-07 00:39:20,957 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 00:39:21,841 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 51% reduce 0%
   [druid] 2018-12-07 00:39:23,959 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 00:39:24,864 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 60% reduce 0%
   [druid] 2018-12-07 00:39:26,662 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 00:39:26,665 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 00:39:26,783 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2136411292_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 00:39:26,786 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 00:39:26,786 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2136411292_0001_m_000000_0' done.
   [druid] 2018-12-07 00:39:26,786 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2136411292_0001_m_000000_0
   [druid] 2018-12-07 00:39:26,787 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 00:39:26,790 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 00:39:26,791 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2136411292_0001_r_000000_0
   [druid] 2018-12-07 00:39:26,801 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 00:39:26,801 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 00:39:26,869 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-12-07 00:39:26,936 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4533c61b
   [druid] 2018-12-07 00:39:26,941 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3efac41a
   [druid] 2018-12-07 00:39:26,962 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 00:39:26,965 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local2136411292_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 00:39:27,015 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local2136411292_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 00:39:27,022 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local2136411292_0001_m_000000_0
   [druid] 2018-12-07 00:39:27,024 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 00:39:27,026 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 00:39:27,027 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 00:39:27,027 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 00:39:27,043 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 00:39:27,043 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 00:39:27,046 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 00:39:27,047 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 00:39:27,048 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 00:39:27,048 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 00:39:27,051 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 00:39:27,052 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 00:39:27,080 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 00:39:27,087 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2136411292_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 00:39:27,088 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 00:39:27,089 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2136411292_0001_r_000000_0' done.
   [druid] 2018-12-07 00:39:27,089 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2136411292_0001_r_000000_0
   [druid] 2018-12-07 00:39:27,089 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 00:39:27,099 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 00:39:27,869 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 00:39:27,869 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local2136411292_0001 completed successfully
   [druid] 2018-12-07 00:39:27,891 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=606410
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=210
		Total committed heap usage (bytes)=764411904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 00:45:43,816 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 00:45:43,819 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 00:45:45,202 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 00:45:45,307 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 00:45:45,368 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 00:45:45,506 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local762148984_0001
   [druid] 2018-12-07 00:45:45,763 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 00:45:45,766 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local762148984_0001
   [druid] 2018-12-07 00:45:45,768 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 00:45:45,780 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 00:45:45,780 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 00:45:45,794 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 00:45:45,864 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 00:45:45,867 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local762148984_0001_m_000000_0
   [druid] 2018-12-07 00:45:45,913 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 00:45:45,921 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 00:45:46,057 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4eefc286
   [druid] 2018-12-07 00:45:46,069 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 00:45:46,162 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 00:45:46,162 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 00:45:46,163 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 00:45:46,163 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 00:45:46,163 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 00:45:46,169 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 00:45:47,210 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local762148984_0001 running in uber mode : false
   [druid] 2018-12-07 00:46:01,629 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 14:49:01,503 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 14:49:01,504 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 14:49:02,278 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 14:49:02,356 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 14:49:02,391 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 14:49:02,480 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1619193750_0001
   [druid] 2018-12-07 14:49:02,694 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 14:49:02,695 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1619193750_0001
   [druid] 2018-12-07 14:49:02,698 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 14:49:02,704 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 14:49:02,704 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 14:49:02,713 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 14:49:02,750 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 14:49:02,752 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1619193750_0001_m_000000_0
   [druid] 2018-12-07 14:49:02,774 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 14:49:02,778 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 14:49:03,698 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1619193750_0001 running in uber mode : false
   [druid] 2018-12-07 14:49:03,699 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 14:49:05,951 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@37d62c8f
   [druid] 2018-12-07 14:49:05,957 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-07 14:49:06,013 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 14:49:06,013 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 14:49:06,013 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 14:49:06,013 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 14:49:06,013 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 14:49:06,017 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 14:49:07,177 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,177 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,177 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,177 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,178 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,178 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,178 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,178 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,178 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,178 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,179 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,179 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,179 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,179 [ask Executor #0] INFO  .TotalMember.TotalMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 14:49:07,822 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-07 14:49:07,909 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 14:49:07,909 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 14:49:07,909 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 400; bufvoid = 104857600
   [druid] 2018-12-07 14:49:07,909 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
   [druid] 2018-12-07 14:49:07,980 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 14:49:07,987 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1619193750_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 14:49:07,994 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 14:49:07,994 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1619193750_0001_m_000000_0' done.
   [druid] 2018-12-07 14:49:07,994 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1619193750_0001_m_000000_0
   [druid] 2018-12-07 14:49:07,994 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 14:49:07,996 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 14:49:07,997 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1619193750_0001_r_000000_0
   [druid] 2018-12-07 14:49:08,005 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 14:49:08,005 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 14:49:08,095 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@380c6b67
   [druid] 2018-12-07 14:49:08,140 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@29da8d44
   [druid] 2018-12-07 14:49:08,155 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 14:49:08,158 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1619193750_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 14:49:08,184 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1619193750_0001_m_000000_0 decomp: 410 len: 414 to MEMORY
   [druid] 2018-12-07 14:49:08,188 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 410 bytes from map-output for attempt_local1619193750_0001_m_000000_0
   [druid] 2018-12-07 14:49:08,190 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 410, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->410
   [druid] 2018-12-07 14:49:08,192 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 14:49:08,192 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 14:49:08,192 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 14:49:08,201 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 14:49:08,201 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 334 bytes
   [druid] 2018-12-07 14:49:08,202 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 410 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 14:49:08,203 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 414 bytes from disk
   [druid] 2018-12-07 14:49:08,204 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 14:49:08,204 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 14:49:08,204 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 334 bytes
   [druid] 2018-12-07 14:49:08,205 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 14:49:08,251 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 14:49:08,404 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1619193750_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 14:49:08,406 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 14:49:08,406 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1619193750_0001_r_000000_0' done.
   [druid] 2018-12-07 14:49:08,406 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1619193750_0001_r_000000_0
   [druid] 2018-12-07 14:49:08,407 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 14:49:08,414 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 14:49:08,704 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 14:49:08,704 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1619193750_0001 completed successfully
   [druid] 2018-12-07 14:49:08,716 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1178
		FILE: Number of bytes written=607632
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=65
		Map output records=4
		Map output bytes=400
		Map output materialized bytes=414
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=414
		Reduce input records=4
		Reduce output records=11
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27156
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 14:58:35,842 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 14:58:35,844 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 14:58:36,481 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 14:58:36,566 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 14:58:36,595 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 14:58:36,680 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local544566821_0001
   [druid] 2018-12-07 14:58:36,820 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 14:58:36,821 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local544566821_0001
   [druid] 2018-12-07 14:58:36,822 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 14:58:36,828 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 14:58:36,828 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 14:58:36,834 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 14:58:36,873 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 14:58:36,874 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local544566821_0001_m_000000_0
   [druid] 2018-12-07 14:58:36,897 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 14:58:36,902 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 14:58:36,985 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@513ac1d3
   [druid] 2018-12-07 14:58:37,044 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-07 14:58:37,090 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 14:58:37,090 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 14:58:37,090 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 14:58:37,090 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 14:58:37,090 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 14:58:37,093 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 14:58:37,515 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-07 14:58:37,517 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 14:58:37,517 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 14:58:37,517 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 6864; bufvoid = 104857600
   [druid] 2018-12-07 14:58:37,517 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214244(104856976); length = 153/6553600
   [druid] 2018-12-07 14:58:37,824 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local544566821_0001 running in uber mode : false
   [druid] 2018-12-07 14:58:37,825 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 14:58:37,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 14:58:37,842 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local544566821_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 14:58:37,850 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 14:58:37,850 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local544566821_0001_m_000000_0' done.
   [druid] 2018-12-07 14:58:37,850 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local544566821_0001_m_000000_0
   [druid] 2018-12-07 14:58:37,850 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 14:58:37,852 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 14:58:37,852 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local544566821_0001_r_000000_0
   [druid] 2018-12-07 14:58:37,859 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 14:58:37,859 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 14:58:37,939 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@240fbe51
   [druid] 2018-12-07 14:58:37,984 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@76d8562f
   [druid] 2018-12-07 14:58:37,999 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 14:58:38,001 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local544566821_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 14:58:38,027 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local544566821_0001_m_000000_0 decomp: 6944 len: 6948 to MEMORY
   [druid] 2018-12-07 14:58:38,032 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 6944 bytes from map-output for attempt_local544566821_0001_m_000000_0
   [druid] 2018-12-07 14:58:38,034 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 6944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->6944
   [druid] 2018-12-07 14:58:38,035 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 14:58:38,036 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 14:58:38,036 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 14:58:38,047 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 14:58:38,047 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6842 bytes
   [druid] 2018-12-07 14:58:38,050 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 6944 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 14:58:38,051 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6948 bytes from disk
   [druid] 2018-12-07 14:58:38,052 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 14:58:38,052 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 14:58:38,053 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6842 bytes
   [druid] 2018-12-07 14:58:38,053 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 14:58:38,296 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 14:58:38,371 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local544566821_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 14:58:38,372 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 14:58:38,372 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local544566821_0001_r_000000_0' done.
   [druid] 2018-12-07 14:58:38,372 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local544566821_0001_r_000000_0
   [druid] 2018-12-07 14:58:38,372 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 14:58:38,377 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 14:58:38,827 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 14:58:38,827 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local544566821_0001 completed successfully
   [druid] 2018-12-07 14:58:38,838 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=14246
		FILE: Number of bytes written=624254
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=65
		Map output records=39
		Map output bytes=6864
		Map output materialized bytes=6948
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=6948
		Reduce input records=39
		Reduce output records=1
		Spilled Records=78
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=600834048
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27156
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 16:15:53,281 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 16:15:53,282 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 16:15:53,893 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 16:15:53,975 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 16:15:54,014 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 16:15:54,103 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local909868966_0001
   [druid] 2018-12-07 16:15:54,280 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 16:15:54,281 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local909868966_0001
   [druid] 2018-12-07 16:15:54,282 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 16:15:54,289 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 16:15:54,289 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 16:15:54,297 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 16:15:54,345 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 16:15:54,348 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local909868966_0001_m_000000_0
   [druid] 2018-12-07 16:15:54,380 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 16:15:54,384 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 16:15:55,283 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local909868966_0001 running in uber mode : false
   [druid] 2018-12-07 16:15:55,284 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 16:15:57,555 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@16894b5c
   [druid] 2018-12-07 16:15:57,562 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-07 16:15:57,608 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 16:15:57,608 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 16:15:57,608 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 16:15:57,608 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 16:15:57,608 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 16:15:57,611 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 16:15:58,085 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-07 16:15:58,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 16:15:58,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 16:15:58,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 6864; bufvoid = 104857600
   [druid] 2018-12-07 16:15:58,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214244(104856976); length = 153/6553600
   [druid] 2018-12-07 16:15:58,098 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 16:15:58,139 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local909868966_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 16:15:58,146 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 16:15:58,146 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local909868966_0001_m_000000_0' done.
   [druid] 2018-12-07 16:15:58,146 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local909868966_0001_m_000000_0
   [druid] 2018-12-07 16:15:58,147 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 16:15:58,149 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 16:15:58,149 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local909868966_0001_r_000000_0
   [druid] 2018-12-07 16:15:58,156 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 16:15:58,156 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 16:15:58,286 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-12-07 16:15:58,361 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@314d403f
   [druid] 2018-12-07 16:15:58,365 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2f720329
   [druid] 2018-12-07 16:15:58,387 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 16:15:58,392 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local909868966_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 16:15:58,429 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local909868966_0001_m_000000_0 decomp: 6944 len: 6948 to MEMORY
   [druid] 2018-12-07 16:15:58,435 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 6944 bytes from map-output for attempt_local909868966_0001_m_000000_0
   [druid] 2018-12-07 16:15:58,437 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 6944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->6944
   [druid] 2018-12-07 16:15:58,438 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 16:15:58,439 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 16:15:58,439 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 16:15:58,449 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 16:15:58,449 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6842 bytes
   [druid] 2018-12-07 16:15:58,451 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 6944 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 16:15:58,452 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6948 bytes from disk
   [druid] 2018-12-07 16:15:58,453 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 16:15:58,453 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 16:15:58,454 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6842 bytes
   [druid] 2018-12-07 16:15:58,455 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 16:15:58,720 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 16:15:58,799 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local909868966_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 16:15:58,800 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 16:15:58,800 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local909868966_0001_r_000000_0' done.
   [druid] 2018-12-07 16:15:58,800 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local909868966_0001_r_000000_0
   [druid] 2018-12-07 16:15:58,801 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 16:15:58,806 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 16:15:59,287 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 16:15:59,287 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local909868966_0001 completed successfully
   [druid] 2018-12-07 16:15:59,300 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=14246
		FILE: Number of bytes written=626578
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=65
		Map output records=39
		Map output bytes=6864
		Map output materialized bytes=6948
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=6948
		Reduce input records=39
		Reduce output records=1
		Spilled Records=78
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=600834048
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27156
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:06:45,709 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:06:45,710 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:06:46,362 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:06:46,427 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:06:46,453 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:06:46,512 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1362529822_0001
   [druid] 2018-12-07 17:06:46,677 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:06:46,678 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1362529822_0001
   [druid] 2018-12-07 17:06:46,679 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:06:46,685 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:06:46,685 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:06:46,691 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:06:46,721 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:06:46,722 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1362529822_0001_m_000000_0
   [druid] 2018-12-07 17:06:46,742 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:06:46,746 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:06:46,873 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@71727f7
   [druid] 2018-12-07 17:06:46,882 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:06:46,931 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:06:46,931 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:06:46,931 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:06:46,931 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:06:46,931 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:06:46,934 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:06:47,680 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1362529822_0001 running in uber mode : false
   [druid] 2018-12-07 17:06:47,681 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:06:52,752 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:06:53,685 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 52% reduce 0%
   [druid] 2018-12-07 17:06:54,847 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:06:54,848 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:06:54,904 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1362529822_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:06:54,906 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:06:54,906 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1362529822_0001_m_000000_0' done.
   [druid] 2018-12-07 17:06:54,906 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1362529822_0001_m_000000_0
   [druid] 2018-12-07 17:06:54,906 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:06:54,908 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:06:54,908 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1362529822_0001_r_000000_0
   [druid] 2018-12-07 17:06:54,914 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:06:54,914 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:06:54,992 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@421cd0e9
   [druid] 2018-12-07 17:06:54,995 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4b432a8e
   [druid] 2018-12-07 17:06:55,008 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:06:55,009 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1362529822_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:06:55,037 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1362529822_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 17:06:55,040 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1362529822_0001_m_000000_0
   [druid] 2018-12-07 17:06:55,041 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 17:06:55,042 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:06:55,043 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:06:55,043 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:06:55,053 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:06:55,053 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:06:55,055 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:06:55,056 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 17:06:55,056 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:06:55,056 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:06:55,059 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:06:55,059 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:06:55,070 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:06:55,074 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1362529822_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:06:55,075 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:06:55,075 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1362529822_0001_r_000000_0' done.
   [druid] 2018-12-07 17:06:55,075 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1362529822_0001_r_000000_0
   [druid] 2018-12-07 17:06:55,075 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:06:55,081 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:06:55,686 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:06:55,686 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1362529822_0001 completed successfully
   [druid] 2018-12-07 17:06:55,697 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=610126
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=59
		Total committed heap usage (bytes)=684720128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:08:32,788 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:08:32,789 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:08:33,447 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:08:33,509 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:08:33,543 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:08:33,622 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local130484365_0001
   [druid] 2018-12-07 17:08:33,764 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:08:33,764 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local130484365_0001
   [druid] 2018-12-07 17:08:33,766 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:08:33,771 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:08:33,771 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:08:33,778 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:08:33,812 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:08:33,814 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local130484365_0001_m_000000_0
   [druid] 2018-12-07 17:08:33,841 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:08:33,847 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:08:33,931 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5a0f2c5f
   [druid] 2018-12-07 17:08:33,942 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:08:33,995 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:08:33,995 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:08:33,995 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:08:33,995 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:08:33,995 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:08:34,001 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:08:34,768 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local130484365_0001 running in uber mode : false
   [druid] 2018-12-07 17:08:34,770 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:08:39,917 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:08:40,774 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 50% reduce 0%
   [druid] 2018-12-07 17:08:42,443 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:08:42,445 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:08:42,551 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local130484365_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:08:42,552 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:08:42,553 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local130484365_0001_m_000000_0' done.
   [druid] 2018-12-07 17:08:42,553 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local130484365_0001_m_000000_0
   [druid] 2018-12-07 17:08:42,553 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:08:42,555 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:08:42,555 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local130484365_0001_r_000000_0
   [druid] 2018-12-07 17:08:42,565 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:08:42,565 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:08:42,644 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@23e9df96
   [druid] 2018-12-07 17:08:42,647 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@473014b1
   [druid] 2018-12-07 17:08:42,663 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:08:42,666 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local130484365_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:08:42,698 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local130484365_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 17:08:42,705 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local130484365_0001_m_000000_0
   [druid] 2018-12-07 17:08:42,708 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 17:08:42,710 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:08:42,711 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:08:42,711 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:08:42,721 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:08:42,723 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:08:42,724 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:08:42,725 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 17:08:42,726 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:08:42,726 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:08:42,728 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:08:42,729 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:08:42,741 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:08:42,745 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local130484365_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:08:42,746 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:08:42,746 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local130484365_0001_r_000000_0' done.
   [druid] 2018-12-07 17:08:42,746 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local130484365_0001_r_000000_0
   [druid] 2018-12-07 17:08:42,746 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:08:42,752 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:08:42,774 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:08:42,774 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local130484365_0001 completed successfully
   [druid] 2018-12-07 17:08:42,792 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=607026
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=52
		Total committed heap usage (bytes)=667942912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:08:57,986 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:08:57,988 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:08:58,658 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:08:58,751 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:08:58,802 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:08:58,902 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local152245053_0001
   [druid] 2018-12-07 17:08:59,030 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:08:59,032 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local152245053_0001
   [druid] 2018-12-07 17:08:59,034 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:08:59,040 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:08:59,040 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:08:59,048 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:08:59,087 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:08:59,089 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local152245053_0001_m_000000_0
   [druid] 2018-12-07 17:08:59,117 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:08:59,123 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:08:59,194 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@17c2ce96
   [druid] 2018-12-07 17:08:59,203 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:08:59,260 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:08:59,260 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:08:59,261 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:08:59,261 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:08:59,261 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:08:59,265 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:09:00,035 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local152245053_0001 running in uber mode : false
   [druid] 2018-12-07 17:09:00,036 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:09:05,186 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:09:06,040 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 50% reduce 0%
   [druid] 2018-12-07 17:09:07,527 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:09:07,529 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:09:07,635 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local152245053_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:09:07,637 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:09:07,637 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local152245053_0001_m_000000_0' done.
   [druid] 2018-12-07 17:09:07,637 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local152245053_0001_m_000000_0
   [druid] 2018-12-07 17:09:07,637 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:09:07,639 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:09:07,640 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local152245053_0001_r_000000_0
   [druid] 2018-12-07 17:09:07,648 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:09:07,648 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:09:07,722 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@76e9528b
   [druid] 2018-12-07 17:09:07,725 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b20e444
   [druid] 2018-12-07 17:09:07,738 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:09:07,742 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local152245053_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:09:07,773 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local152245053_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 17:09:07,780 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local152245053_0001_m_000000_0
   [druid] 2018-12-07 17:09:07,782 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 17:09:07,784 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:09:07,785 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:09:07,785 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:09:07,795 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:09:07,796 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:09:07,798 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:09:07,798 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 17:09:07,799 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:09:07,799 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:09:07,801 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:09:07,802 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:09:07,812 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:09:07,816 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local152245053_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:09:07,817 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:09:07,818 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local152245053_0001_r_000000_0' done.
   [druid] 2018-12-07 17:09:07,818 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local152245053_0001_r_000000_0
   [druid] 2018-12-07 17:09:07,818 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:09:07,823 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:09:08,041 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:09:08,041 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local152245053_0001 completed successfully
   [druid] 2018-12-07 17:09:08,057 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=607026
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=52
		Total committed heap usage (bytes)=665845760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:12:16,771 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:12:16,772 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:12:17,390 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:12:17,457 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:12:17,483 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:12:17,554 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local969845958_0001
   [druid] 2018-12-07 17:12:17,674 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:12:17,674 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local969845958_0001
   [druid] 2018-12-07 17:12:17,675 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:12:17,680 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:12:17,680 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:12:17,686 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:12:17,714 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:12:17,715 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local969845958_0001_m_000000_0
   [druid] 2018-12-07 17:12:17,736 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:12:17,739 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:12:17,808 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@611c21b3
   [druid] 2018-12-07 17:12:17,815 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:12:17,859 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:12:17,859 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:12:17,859 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:12:17,859 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:12:17,859 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:12:17,862 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:12:18,676 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local969845958_0001 running in uber mode : false
   [druid] 2018-12-07 17:12:18,677 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:12:23,812 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:12:24,681 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 34% reduce 0%
   [druid] 2018-12-07 17:12:26,814 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:12:27,682 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 43% reduce 0%
   [druid] 2018-12-07 17:12:29,814 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:12:30,683 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 52% reduce 0%
   [druid] 2018-12-07 17:12:32,815 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:12:33,684 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 62% reduce 0%
   [druid] 2018-12-07 17:12:34,378 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:12:34,380 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:12:34,380 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 17:12:34,380 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 190372; bufvoid = 104857600
   [druid] 2018-12-07 17:12:34,380 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26210548(104842192); length = 3849/6553600
   [druid] 2018-12-07 17:12:34,490 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 17:12:34,523 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local969845958_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:12:34,525 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:12:34,525 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local969845958_0001_m_000000_0' done.
   [druid] 2018-12-07 17:12:34,525 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local969845958_0001_m_000000_0
   [druid] 2018-12-07 17:12:34,525 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:12:34,526 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:12:34,527 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local969845958_0001_r_000000_0
   [druid] 2018-12-07 17:12:34,534 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:12:34,534 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:12:34,613 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3566f813
   [druid] 2018-12-07 17:12:34,616 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@29015e0c
   [druid] 2018-12-07 17:12:34,627 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:12:34,629 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local969845958_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:12:34,652 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local969845958_0001_m_000000_0 decomp: 192300 len: 192304 to MEMORY
   [druid] 2018-12-07 17:12:34,655 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 192300 bytes from map-output for attempt_local969845958_0001_m_000000_0
   [druid] 2018-12-07 17:12:34,656 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 192300, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->192300
   [druid] 2018-12-07 17:12:34,657 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:12:34,658 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:12:34,658 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:12:34,666 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:12:34,666 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 192195 bytes
   [druid] 2018-12-07 17:12:34,670 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 192300 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:12:34,670 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 192304 bytes from disk
   [druid] 2018-12-07 17:12:34,671 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:12:34,671 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:12:34,672 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 192195 bytes
   [druid] 2018-12-07 17:12:34,672 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:12:34,680 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:12:34,684 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-12-07 17:12:34,695 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local969845958_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:12:34,696 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:12:34,696 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local969845958_0001_r_000000_0' done.
   [druid] 2018-12-07 17:12:34,696 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local969845958_0001_r_000000_0
   [druid] 2018-12-07 17:12:34,697 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:12:34,703 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:12:35,685 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:12:35,685 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local969845958_0001 completed successfully
   [druid] 2018-12-07 17:12:35,696 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=384960
		FILE: Number of bytes written=1183920
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=963
		Map output bytes=190372
		Map output materialized bytes=192304
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=192304
		Reduce input records=963
		Reduce output records=1
		Spilled Records=1926
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=120
		Total committed heap usage (bytes)=786432000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:13:27,669 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:13:27,671 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:13:28,356 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:13:28,424 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:13:28,450 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:13:28,512 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local4357830_0001
   [druid] 2018-12-07 17:13:28,635 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:13:28,636 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local4357830_0001
   [druid] 2018-12-07 17:13:28,637 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:13:28,641 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:13:28,642 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:13:28,646 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:13:28,676 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:13:28,677 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local4357830_0001_m_000000_0
   [druid] 2018-12-07 17:13:28,694 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:13:28,698 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:13:28,765 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3b1a9c30
   [druid] 2018-12-07 17:13:28,772 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:13:28,817 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:13:28,817 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:13:28,817 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:13:28,817 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:13:28,817 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:13:28,820 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:13:29,639 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local4357830_0001 running in uber mode : false
   [druid] 2018-12-07 17:13:29,641 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:15:23,494 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:15:23,495 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:15:24,224 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:15:24,301 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:15:24,422 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:15:24,503 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1083920132_0001
   [druid] 2018-12-07 17:15:24,626 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:15:24,627 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1083920132_0001
   [druid] 2018-12-07 17:15:24,628 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:15:24,634 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:15:24,634 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:15:24,640 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:15:24,675 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:15:24,676 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1083920132_0001_m_000000_0
   [druid] 2018-12-07 17:15:24,695 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:15:24,698 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:15:24,768 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@337af943
   [druid] 2018-12-07 17:15:24,775 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:15:24,821 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:15:24,821 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:15:24,821 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:15:24,821 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:15:24,821 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:15:24,824 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:15:25,630 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1083920132_0001 running in uber mode : false
   [druid] 2018-12-07 17:15:25,631 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:16:13,987 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:16:13,988 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:16:14,574 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:16:14,645 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:16:14,673 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:16:14,735 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local534569411_0001
   [druid] 2018-12-07 17:16:14,846 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:16:14,847 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local534569411_0001
   [druid] 2018-12-07 17:16:14,848 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:16:14,851 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:16:14,851 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:16:14,856 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:16:14,885 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:16:14,886 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local534569411_0001_m_000000_0
   [druid] 2018-12-07 17:16:14,908 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:16:14,912 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:16:14,983 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4fe5e6a0
   [druid] 2018-12-07 17:16:14,990 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:16:15,035 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:16:15,035 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:16:15,035 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:16:15,035 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:16:15,035 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:16:15,038 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:16:15,848 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local534569411_0001 running in uber mode : false
   [druid] 2018-12-07 17:16:15,849 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:16:20,920 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:16:21,852 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 51% reduce 0%
   [druid] 2018-12-07 17:16:23,200 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:16:23,202 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:16:23,202 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 17:16:23,202 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 362; bufvoid = 104857600
   [druid] 2018-12-07 17:16:23,202 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2018-12-07 17:16:23,212 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 17:16:23,217 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local534569411_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:16:23,218 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:16:23,219 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local534569411_0001_m_000000_0' done.
   [druid] 2018-12-07 17:16:23,219 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local534569411_0001_m_000000_0
   [druid] 2018-12-07 17:16:23,219 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:16:23,221 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:16:23,221 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local534569411_0001_r_000000_0
   [druid] 2018-12-07 17:16:23,229 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:16:23,229 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:16:23,303 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6fc9874
   [druid] 2018-12-07 17:16:23,306 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42c54c4a
   [druid] 2018-12-07 17:16:23,317 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:16:23,318 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local534569411_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:16:23,344 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local534569411_0001_m_000000_0 decomp: 368 len: 372 to MEMORY
   [druid] 2018-12-07 17:16:23,347 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 368 bytes from map-output for attempt_local534569411_0001_m_000000_0
   [druid] 2018-12-07 17:16:23,348 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 368, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->368
   [druid] 2018-12-07 17:16:23,350 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:16:23,350 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:16:23,350 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:16:23,359 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:16:23,359 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 17:16:23,360 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 368 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:16:23,361 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 372 bytes from disk
   [druid] 2018-12-07 17:16:23,361 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:16:23,361 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:16:23,362 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 17:16:23,363 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:16:23,371 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:16:23,426 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local534569411_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:16:23,427 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:16:23,427 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local534569411_0001_r_000000_0' done.
   [druid] 2018-12-07 17:16:23,427 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local534569411_0001_r_000000_0
   [druid] 2018-12-07 17:16:23,427 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:16:23,433 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:16:23,853 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:16:23,853 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local534569411_0001 completed successfully
   [druid] 2018-12-07 17:16:23,864 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1096
		FILE: Number of bytes written=608112
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=2
		Map output bytes=362
		Map output materialized bytes=372
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=372
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=49
		Total committed heap usage (bytes)=685768704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:17:50,847 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:17:50,848 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:17:51,401 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:17:51,471 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:17:51,498 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:17:51,564 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local743511447_0001
   [druid] 2018-12-07 17:17:51,672 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:17:51,672 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local743511447_0001
   [druid] 2018-12-07 17:17:51,673 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:17:51,677 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:17:51,677 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:17:51,681 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:17:51,711 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:17:51,712 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local743511447_0001_m_000000_0
   [druid] 2018-12-07 17:17:51,732 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:17:51,735 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:17:51,807 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3f2b179f
   [druid] 2018-12-07 17:17:51,814 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:17:51,858 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:17:51,858 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:17:51,858 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:17:51,858 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:17:51,858 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:17:51,861 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:17:52,675 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local743511447_0001 running in uber mode : false
   [druid] 2018-12-07 17:17:52,676 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:17:57,741 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:17:58,678 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 51% reduce 0%
   [druid] 2018-12-07 17:18:00,013 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:18:00,014 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:18:00,118 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local743511447_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:18:00,119 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:18:00,119 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local743511447_0001_m_000000_0' done.
   [druid] 2018-12-07 17:18:00,119 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local743511447_0001_m_000000_0
   [druid] 2018-12-07 17:18:00,119 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:18:00,121 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:18:00,121 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local743511447_0001_r_000000_0
   [druid] 2018-12-07 17:18:00,128 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:18:00,128 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:18:00,201 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@479b6aab
   [druid] 2018-12-07 17:18:00,204 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@363babe5
   [druid] 2018-12-07 17:18:00,220 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:18:00,222 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local743511447_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:18:00,251 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local743511447_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 17:18:00,255 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local743511447_0001_m_000000_0
   [druid] 2018-12-07 17:18:00,256 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 17:18:00,258 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:18:00,259 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:18:00,259 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:18:00,269 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:18:00,269 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:18:00,271 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:18:00,272 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 17:18:00,272 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:18:00,272 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:18:00,274 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:18:00,275 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:18:00,285 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:18:00,288 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local743511447_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:18:00,289 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:18:00,289 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local743511447_0001_r_000000_0' done.
   [druid] 2018-12-07 17:18:00,289 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local743511447_0001_r_000000_0
   [druid] 2018-12-07 17:18:00,289 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:18:00,293 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:18:00,679 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:18:00,679 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local743511447_0001 completed successfully
   [druid] 2018-12-07 17:18:00,690 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=607014
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=50
		Total committed heap usage (bytes)=685768704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:18:33,863 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:18:33,865 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:18:34,412 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:18:34,491 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:18:34,519 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:18:34,614 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local703974504_0001
   [druid] 2018-12-07 17:18:34,753 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:18:34,754 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local703974504_0001
   [druid] 2018-12-07 17:18:34,756 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:18:34,762 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:18:34,762 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:18:34,767 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:18:34,798 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:18:34,800 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local703974504_0001_m_000000_0
   [druid] 2018-12-07 17:18:34,819 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:18:34,823 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:18:34,896 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4b105acb
   [druid] 2018-12-07 17:18:34,903 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:18:34,950 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:18:34,950 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:18:34,950 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:18:34,950 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:18:34,950 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:18:34,953 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:18:35,757 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local703974504_0001 running in uber mode : false
   [druid] 2018-12-07 17:18:35,758 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:18:40,843 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:18:41,762 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 50% reduce 0%
   [druid] 2018-12-07 17:18:43,308 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:18:43,310 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:18:43,310 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 17:18:43,310 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 362; bufvoid = 104857600
   [druid] 2018-12-07 17:18:43,310 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2018-12-07 17:18:43,410 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 17:18:43,416 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local703974504_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:18:43,417 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:18:43,417 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local703974504_0001_m_000000_0' done.
   [druid] 2018-12-07 17:18:43,417 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local703974504_0001_m_000000_0
   [druid] 2018-12-07 17:18:43,417 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:18:43,419 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:18:43,419 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local703974504_0001_r_000000_0
   [druid] 2018-12-07 17:18:43,426 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:18:43,426 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:18:43,505 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@218de905
   [druid] 2018-12-07 17:18:43,508 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6449a6ac
   [druid] 2018-12-07 17:18:43,521 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:18:43,523 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local703974504_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:18:43,559 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local703974504_0001_m_000000_0 decomp: 368 len: 372 to MEMORY
   [druid] 2018-12-07 17:18:43,566 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 368 bytes from map-output for attempt_local703974504_0001_m_000000_0
   [druid] 2018-12-07 17:18:43,568 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 368, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->368
   [druid] 2018-12-07 17:18:43,569 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:18:43,569 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:18:43,569 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:18:43,579 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:18:43,579 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 17:18:43,582 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 368 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:18:43,583 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 372 bytes from disk
   [druid] 2018-12-07 17:18:43,584 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:18:43,584 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:18:43,585 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 17:18:43,585 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:18:43,597 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:18:43,651 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local703974504_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:18:43,652 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:18:43,652 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local703974504_0001_r_000000_0' done.
   [druid] 2018-12-07 17:18:43,652 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local703974504_0001_r_000000_0
   [druid] 2018-12-07 17:18:43,652 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:18:43,659 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:18:43,763 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:18:43,764 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local703974504_0001 completed successfully
   [druid] 2018-12-07 17:18:43,780 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1096
		FILE: Number of bytes written=608112
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=2
		Map output bytes=362
		Map output materialized bytes=372
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=372
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=54
		Total committed heap usage (bytes)=689963008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:21:28,663 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:21:28,664 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:21:29,251 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:21:29,320 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:21:29,366 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:21:29,429 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local62651935_0001
   [druid] 2018-12-07 17:21:29,539 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:21:29,540 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local62651935_0001
   [druid] 2018-12-07 17:21:29,540 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:21:29,544 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:21:29,544 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:21:29,549 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:21:29,574 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:21:29,576 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local62651935_0001_m_000000_0
   [druid] 2018-12-07 17:21:29,596 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:21:29,599 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:21:29,667 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7e65b385
   [druid] 2018-12-07 17:21:29,673 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:21:29,717 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:21:29,717 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:21:29,717 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:21:29,717 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:21:29,717 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:21:29,720 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:21:30,542 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local62651935_0001 running in uber mode : false
   [druid] 2018-12-07 17:21:30,543 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:21:35,606 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:21:36,547 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 50% reduce 0%
   [druid] 2018-12-07 17:21:37,879 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:21:37,881 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:21:37,990 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local62651935_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:21:37,991 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:21:37,991 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local62651935_0001_m_000000_0' done.
   [druid] 2018-12-07 17:21:37,991 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local62651935_0001_m_000000_0
   [druid] 2018-12-07 17:21:37,992 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:21:37,993 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:21:37,994 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local62651935_0001_r_000000_0
   [druid] 2018-12-07 17:21:37,999 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:21:37,999 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:21:38,077 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2e4e714f
   [druid] 2018-12-07 17:21:38,080 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e9d3535
   [druid] 2018-12-07 17:21:38,095 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:21:38,097 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local62651935_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:21:38,130 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local62651935_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 17:21:38,135 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local62651935_0001_m_000000_0
   [druid] 2018-12-07 17:21:38,137 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 17:21:38,139 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:21:38,139 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:21:38,139 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:21:38,150 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:21:38,150 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:21:38,152 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:21:38,153 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 17:21:38,154 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:21:38,154 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:21:38,157 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:21:38,157 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:21:38,168 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:21:38,174 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local62651935_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:21:38,175 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:21:38,175 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local62651935_0001_r_000000_0' done.
   [druid] 2018-12-07 17:21:38,175 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local62651935_0001_r_000000_0
   [druid] 2018-12-07 17:21:38,176 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:21:38,181 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:21:38,548 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:21:38,548 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local62651935_0001 completed successfully
   [druid] 2018-12-07 17:21:38,558 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=603922
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=52
		Total committed heap usage (bytes)=689963008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:22:04,084 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:22:04,087 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:22:04,798 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:22:04,868 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:22:04,896 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:22:04,955 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local2086544750_0001
   [druid] 2018-12-07 17:22:05,118 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:22:05,119 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local2086544750_0001
   [druid] 2018-12-07 17:22:05,120 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:22:05,125 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:22:05,125 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:22:05,132 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:22:05,161 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:22:05,163 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2086544750_0001_m_000000_0
   [druid] 2018-12-07 17:22:05,185 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:22:05,189 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:22:05,255 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@74c06463
   [druid] 2018-12-07 17:22:05,262 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:22:05,309 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:22:05,309 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:22:05,309 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:22:05,309 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:22:05,309 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:22:05,313 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:22:06,120 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local2086544750_0001 running in uber mode : false
   [druid] 2018-12-07 17:22:06,121 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:22:11,195 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:22:12,124 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 51% reduce 0%
   [druid] 2018-12-07 17:22:13,304 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:22:13,305 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:22:13,305 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 17:22:13,305 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 362; bufvoid = 104857600
   [druid] 2018-12-07 17:22:13,306 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2018-12-07 17:22:13,421 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 17:22:13,428 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2086544750_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:22:13,429 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:22:13,429 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2086544750_0001_m_000000_0' done.
   [druid] 2018-12-07 17:22:13,429 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2086544750_0001_m_000000_0
   [druid] 2018-12-07 17:22:13,430 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:22:13,432 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:22:13,432 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2086544750_0001_r_000000_0
   [druid] 2018-12-07 17:22:13,444 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:22:13,444 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:22:13,543 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@255fa39c
   [druid] 2018-12-07 17:22:13,547 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7776861f
   [druid] 2018-12-07 17:22:13,561 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:22:13,564 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local2086544750_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:22:13,598 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local2086544750_0001_m_000000_0 decomp: 368 len: 372 to MEMORY
   [druid] 2018-12-07 17:22:13,603 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 368 bytes from map-output for attempt_local2086544750_0001_m_000000_0
   [druid] 2018-12-07 17:22:13,604 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 368, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->368
   [druid] 2018-12-07 17:22:13,605 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:22:13,606 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:22:13,606 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:22:13,616 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:22:13,617 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 17:22:13,619 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 368 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:22:13,619 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 372 bytes from disk
   [druid] 2018-12-07 17:22:13,620 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:22:13,620 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:22:13,621 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 17:22:13,621 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:22:13,631 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:22:13,705 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2086544750_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:22:13,706 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:22:13,706 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2086544750_0001_r_000000_0' done.
   [druid] 2018-12-07 17:22:13,706 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2086544750_0001_r_000000_0
   [druid] 2018-12-07 17:22:13,706 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:22:13,713 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:22:14,125 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:22:14,125 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local2086544750_0001 completed successfully
   [druid] 2018-12-07 17:22:14,136 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1096
		FILE: Number of bytes written=611220
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=2
		Map output bytes=362
		Map output materialized bytes=372
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=372
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=50
		Total committed heap usage (bytes)=684720128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:23:23,858 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:23:23,859 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:23:24,484 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:23:24,557 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:23:24,588 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:23:24,675 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local169806903_0001
   [druid] 2018-12-07 17:23:24,801 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:23:24,802 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local169806903_0001
   [druid] 2018-12-07 17:23:24,803 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:23:24,807 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:23:24,807 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:23:24,812 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:23:24,844 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:23:24,845 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local169806903_0001_m_000000_0
   [druid] 2018-12-07 17:23:24,863 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:23:24,867 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:23:24,934 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3f2b179f
   [druid] 2018-12-07 17:23:24,942 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:23:24,986 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:23:24,986 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:23:24,986 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:23:24,986 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:23:24,986 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:23:24,990 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:23:25,804 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local169806903_0001 running in uber mode : false
   [druid] 2018-12-07 17:23:25,805 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:23:30,933 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:23:31,809 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 50% reduce 0%
   [druid] 2018-12-07 17:23:33,218 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:23:33,220 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:23:33,220 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 17:23:33,220 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 362; bufvoid = 104857600
   [druid] 2018-12-07 17:23:33,220 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2018-12-07 17:23:33,329 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 17:23:33,335 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local169806903_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:23:33,337 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:23:33,337 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local169806903_0001_m_000000_0' done.
   [druid] 2018-12-07 17:23:33,337 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local169806903_0001_m_000000_0
   [druid] 2018-12-07 17:23:33,337 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:23:33,339 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:23:33,339 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local169806903_0001_r_000000_0
   [druid] 2018-12-07 17:23:33,346 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:23:33,346 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:23:33,421 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6bb7b8be
   [druid] 2018-12-07 17:23:33,424 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@cda2dd8
   [druid] 2018-12-07 17:23:33,438 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:23:33,440 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local169806903_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:23:33,469 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local169806903_0001_m_000000_0 decomp: 368 len: 372 to MEMORY
   [druid] 2018-12-07 17:23:33,473 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 368 bytes from map-output for attempt_local169806903_0001_m_000000_0
   [druid] 2018-12-07 17:23:33,474 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 368, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->368
   [druid] 2018-12-07 17:23:33,475 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:23:33,476 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:23:33,476 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:23:33,486 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:23:33,486 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 17:23:33,493 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 368 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:23:33,496 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 372 bytes from disk
   [druid] 2018-12-07 17:23:33,496 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:23:33,496 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:23:33,498 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 17:23:33,498 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:23:33,509 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:23:33,574 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local169806903_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:23:33,575 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:23:33,575 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local169806903_0001_r_000000_0' done.
   [druid] 2018-12-07 17:23:33,575 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local169806903_0001_r_000000_0
   [druid] 2018-12-07 17:23:33,575 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:23:33,580 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:23:33,810 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:23:33,810 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local169806903_0001 completed successfully
   [druid] 2018-12-07 17:23:33,821 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1096
		FILE: Number of bytes written=608124
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=2
		Map output bytes=362
		Map output materialized bytes=372
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=372
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=55
		Total committed heap usage (bytes)=686817280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:29:12,749 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:29:12,750 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:29:13,381 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:29:13,454 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:29:13,483 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:29:13,549 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1267154349_0001
   [druid] 2018-12-07 17:29:13,666 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:29:13,667 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1267154349_0001
   [druid] 2018-12-07 17:29:13,668 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:29:13,673 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:29:13,673 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:29:13,677 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:29:13,707 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:29:13,709 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1267154349_0001_m_000000_0
   [druid] 2018-12-07 17:29:13,733 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:29:13,738 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:29:13,813 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7977cd1f
   [druid] 2018-12-07 17:29:13,824 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:29:13,871 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:29:13,871 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:29:13,871 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:29:13,871 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:29:13,871 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:29:13,874 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:29:14,670 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1267154349_0001 running in uber mode : false
   [druid] 2018-12-07 17:29:14,671 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:29:19,803 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:29:20,676 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 50% reduce 0%
   [druid] 2018-12-07 17:29:22,376 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:29:22,378 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:29:22,415 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1267154349_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:29:22,416 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:29:22,416 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1267154349_0001_m_000000_0' done.
   [druid] 2018-12-07 17:29:22,416 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1267154349_0001_m_000000_0
   [druid] 2018-12-07 17:29:22,416 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:29:22,418 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:29:22,418 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1267154349_0001_r_000000_0
   [druid] 2018-12-07 17:29:22,424 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:29:22,424 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:29:22,500 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@27dc7e5
   [druid] 2018-12-07 17:29:22,503 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3c68b997
   [druid] 2018-12-07 17:29:22,516 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:29:22,518 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1267154349_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:29:22,545 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1267154349_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 17:29:22,550 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1267154349_0001_m_000000_0
   [druid] 2018-12-07 17:29:22,551 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 17:29:22,553 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:29:22,553 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:29:22,554 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:29:22,562 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:29:22,562 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:29:22,564 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:29:22,565 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 17:29:22,565 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:29:22,565 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:29:22,567 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:29:22,568 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:29:22,577 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:29:22,580 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1267154349_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:29:22,581 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:29:22,581 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1267154349_0001_r_000000_0' done.
   [druid] 2018-12-07 17:29:22,581 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1267154349_0001_r_000000_0
   [druid] 2018-12-07 17:29:22,581 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:29:22,586 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:29:22,676 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:29:22,676 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1267154349_0001 completed successfully
   [druid] 2018-12-07 17:29:22,687 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=610126
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=55
		Total committed heap usage (bytes)=688914432
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:30:51,592 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:30:51,593 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:30:52,173 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:30:52,246 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:30:52,273 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:30:52,332 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1116410380_0001
   [druid] 2018-12-07 17:30:52,443 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:30:52,444 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1116410380_0001
   [druid] 2018-12-07 17:30:52,445 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:30:52,449 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:30:52,449 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:30:52,454 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:30:52,486 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:30:52,487 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1116410380_0001_m_000000_0
   [druid] 2018-12-07 17:30:52,506 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:30:52,510 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:30:52,580 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@199395bd
   [druid] 2018-12-07 17:30:52,587 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:30:52,632 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:30:52,632 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:30:52,632 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:30:52,632 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:30:52,632 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:30:52,634 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:30:53,447 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1116410380_0001 running in uber mode : false
   [druid] 2018-12-07 17:30:53,448 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:34:07,157 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:34:07,159 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:34:07,718 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:34:07,788 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:34:07,906 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:34:07,973 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local543540877_0001
   [druid] 2018-12-07 17:34:08,093 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:34:08,094 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local543540877_0001
   [druid] 2018-12-07 17:34:08,095 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:34:08,100 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:34:08,100 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:34:08,105 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:34:08,134 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:34:08,135 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local543540877_0001_m_000000_0
   [druid] 2018-12-07 17:34:08,154 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:34:08,158 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:34:08,230 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@337af943
   [druid] 2018-12-07 17:34:08,237 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:34:08,281 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:34:08,281 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:34:08,281 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:34:08,281 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:34:08,281 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:34:08,285 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:34:09,096 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local543540877_0001 running in uber mode : false
   [druid] 2018-12-07 17:34:09,097 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:36:54,303 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:36:54,304 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:36:54,861 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:36:54,929 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:36:55,046 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:36:55,103 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local420120435_0001
   [druid] 2018-12-07 17:36:55,213 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:36:55,213 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local420120435_0001
   [druid] 2018-12-07 17:36:55,214 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:36:55,219 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:36:55,219 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:36:55,224 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:36:55,251 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:36:55,253 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local420120435_0001_m_000000_0
   [druid] 2018-12-07 17:36:55,272 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:36:55,274 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:36:55,406 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5b7f33dc
   [druid] 2018-12-07 17:36:55,413 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:36:55,456 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:36:55,456 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:36:55,456 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:36:55,457 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:36:55,457 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:36:55,460 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:36:56,215 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local420120435_0001 running in uber mode : false
   [druid] 2018-12-07 17:36:56,216 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:38:36,315 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:38:36,317 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:38:36,875 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:38:36,941 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:38:37,066 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:38:37,128 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local666646419_0001
   [druid] 2018-12-07 17:38:37,240 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:38:37,241 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local666646419_0001
   [druid] 2018-12-07 17:38:37,241 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:38:37,245 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:38:37,245 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:38:37,250 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:38:37,278 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:38:37,280 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local666646419_0001_m_000000_0
   [druid] 2018-12-07 17:38:37,296 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:38:37,300 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:38:37,373 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3c6b45a2
   [druid] 2018-12-07 17:38:37,381 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:38:37,425 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:38:37,425 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:38:37,425 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:38:37,425 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:38:37,425 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:38:37,428 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:38:38,242 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local666646419_0001 running in uber mode : false
   [druid] 2018-12-07 17:38:38,243 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:39:51,709 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:39:51,710 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:39:52,284 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:39:52,351 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:39:52,467 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:39:52,530 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local2114796117_0001
   [druid] 2018-12-07 17:39:52,640 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:39:52,641 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local2114796117_0001
   [druid] 2018-12-07 17:39:52,642 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:39:52,647 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:39:52,647 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:39:52,652 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:39:52,678 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:39:52,679 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2114796117_0001_m_000000_0
   [druid] 2018-12-07 17:39:52,697 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:39:52,701 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:39:52,779 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7977cd1f
   [druid] 2018-12-07 17:39:52,786 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:39:52,837 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:39:52,837 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:39:52,837 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:39:52,837 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:39:52,837 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:39:52,840 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:39:53,643 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local2114796117_0001 running in uber mode : false
   [druid] 2018-12-07 17:39:53,644 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:42:52,674 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:42:52,676 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:42:53,338 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:42:53,430 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:42:53,481 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:42:53,566 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1631865544_0001
   [druid] 2018-12-07 17:42:53,708 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:42:53,709 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1631865544_0001
   [druid] 2018-12-07 17:42:53,710 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:42:53,715 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:42:53,715 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:42:53,720 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:42:53,754 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:42:53,756 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1631865544_0001_m_000000_0
   [druid] 2018-12-07 17:42:53,779 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:42:53,782 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:42:53,854 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4b105acb
   [druid] 2018-12-07 17:42:53,862 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:42:53,911 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:42:53,911 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:42:53,911 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:42:53,911 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:42:53,911 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:42:53,914 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:42:54,712 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1631865544_0001 running in uber mode : false
   [druid] 2018-12-07 17:42:54,713 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:43:33,705 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:43:33,707 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:43:34,267 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:43:34,335 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:43:34,451 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:43:34,527 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local588360265_0001
   [druid] 2018-12-07 17:43:34,642 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:43:34,643 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local588360265_0001
   [druid] 2018-12-07 17:43:34,644 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:43:34,649 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:43:34,649 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:43:34,653 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:43:34,681 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:43:34,682 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local588360265_0001_m_000000_0
   [druid] 2018-12-07 17:43:34,700 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:43:34,703 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:43:34,774 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@56ae32c0
   [druid] 2018-12-07 17:43:34,780 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:43:34,824 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:43:34,824 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:43:34,824 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:43:34,824 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:43:34,824 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:43:34,827 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:43:35,644 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local588360265_0001 running in uber mode : false
   [druid] 2018-12-07 17:43:35,645 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:45:01,497 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:45:01,499 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:45:02,072 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:45:02,145 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:45:02,263 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:45:02,324 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1291597589_0001
   [druid] 2018-12-07 17:45:02,438 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:45:02,438 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1291597589_0001
   [druid] 2018-12-07 17:45:02,440 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:45:02,445 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:45:02,445 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:45:02,449 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:45:02,475 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:45:02,476 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1291597589_0001_m_000000_0
   [druid] 2018-12-07 17:45:02,496 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:45:02,501 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:45:02,571 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@611c21b3
   [druid] 2018-12-07 17:45:02,578 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:45:02,623 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:45:02,623 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:45:02,623 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:45:02,623 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:45:02,623 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:45:02,627 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:45:03,441 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1291597589_0001 running in uber mode : false
   [druid] 2018-12-07 17:45:03,442 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:45:52,816 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:45:52,817 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:45:53,368 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:45:53,440 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:45:53,486 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:45:53,548 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1749485316_0001
   [druid] 2018-12-07 17:45:53,663 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:45:53,664 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1749485316_0001
   [druid] 2018-12-07 17:45:53,665 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:45:53,670 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:45:53,670 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:45:53,676 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:45:53,706 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:45:53,707 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1749485316_0001_m_000000_0
   [druid] 2018-12-07 17:45:53,730 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:45:53,733 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:45:53,804 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1da26058
   [druid] 2018-12-07 17:45:53,811 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:45:53,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:45:53,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:45:53,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:45:53,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:45:53,855 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:45:53,857 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:45:54,667 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1749485316_0001 running in uber mode : false
   [druid] 2018-12-07 17:45:54,668 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:52:54,464 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:52:54,465 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:52:55,110 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:52:55,186 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:52:55,216 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:52:55,282 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local664356568_0001
   [druid] 2018-12-07 17:52:55,416 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:52:55,417 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local664356568_0001
   [druid] 2018-12-07 17:52:55,418 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:52:55,425 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:52:55,425 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:52:55,430 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:52:55,455 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:52:55,456 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local664356568_0001_m_000000_0
   [druid] 2018-12-07 17:52:55,474 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:52:55,478 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:52:55,551 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7977cd1f
   [druid] 2018-12-07 17:52:55,557 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:52:55,602 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:52:55,602 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:52:55,602 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:52:55,602 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:52:55,602 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:52:55,605 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:52:56,419 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local664356568_0001 running in uber mode : false
   [druid] 2018-12-07 17:52:56,420 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:53:01,482 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:53:02,424 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 51% reduce 0%
   [druid] 2018-12-07 17:53:03,748 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:53:03,749 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:53:03,749 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 17:53:03,749 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 362; bufvoid = 104857600
   [druid] 2018-12-07 17:53:03,750 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2018-12-07 17:53:03,844 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 17:53:03,867 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local664356568_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:53:03,869 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:53:03,869 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local664356568_0001_m_000000_0' done.
   [druid] 2018-12-07 17:53:03,869 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local664356568_0001_m_000000_0
   [druid] 2018-12-07 17:53:03,869 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:53:03,871 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:53:03,871 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local664356568_0001_r_000000_0
   [druid] 2018-12-07 17:53:03,878 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:53:03,878 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:53:03,953 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@495c485a
   [druid] 2018-12-07 17:53:03,956 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@560526bb
   [druid] 2018-12-07 17:53:03,968 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:53:03,970 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local664356568_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:53:04,000 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local664356568_0001_m_000000_0 decomp: 368 len: 372 to MEMORY
   [druid] 2018-12-07 17:53:04,004 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 368 bytes from map-output for attempt_local664356568_0001_m_000000_0
   [druid] 2018-12-07 17:53:04,005 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 368, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->368
   [druid] 2018-12-07 17:53:04,006 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:53:04,007 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:53:04,008 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:53:04,016 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:53:04,016 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 17:53:04,019 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 368 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:53:04,019 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 372 bytes from disk
   [druid] 2018-12-07 17:53:04,020 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:53:04,020 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:53:04,021 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 17:53:04,022 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:53:04,033 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:53:04,099 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local664356568_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:53:04,101 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:53:04,101 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local664356568_0001_r_000000_0' done.
   [druid] 2018-12-07 17:53:04,101 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local664356568_0001_r_000000_0
   [druid] 2018-12-07 17:53:04,101 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:53:04,107 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:53:04,425 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:53:04,425 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local664356568_0001 completed successfully
   [druid] 2018-12-07 17:53:04,437 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1096
		FILE: Number of bytes written=608120
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=2
		Map output bytes=362
		Map output materialized bytes=372
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=372
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=49
		Total committed heap usage (bytes)=697303040
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:53:28,604 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:53:28,606 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:53:29,169 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:53:29,241 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:53:29,267 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:53:29,330 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1002815220_0001
   [druid] 2018-12-07 17:53:29,437 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:53:29,437 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1002815220_0001
   [druid] 2018-12-07 17:53:29,438 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:53:29,443 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:53:29,443 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:53:29,449 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:53:29,477 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:53:29,478 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1002815220_0001_m_000000_0
   [druid] 2018-12-07 17:53:29,500 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:53:29,504 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:53:29,572 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1da26058
   [druid] 2018-12-07 17:53:29,579 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:53:29,624 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:53:29,624 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:53:29,624 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:53:29,624 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:53:29,624 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:53:29,626 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:53:30,439 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1002815220_0001 running in uber mode : false
   [druid] 2018-12-07 17:53:30,440 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:53:35,510 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:53:36,443 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 51% reduce 0%
   [druid] 2018-12-07 17:53:37,677 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:53:37,678 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:53:37,737 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1002815220_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:53:37,738 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:53:37,739 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1002815220_0001_m_000000_0' done.
   [druid] 2018-12-07 17:53:37,739 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1002815220_0001_m_000000_0
   [druid] 2018-12-07 17:53:37,739 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:53:37,741 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:53:37,741 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1002815220_0001_r_000000_0
   [druid] 2018-12-07 17:53:37,747 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:53:37,747 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:53:37,824 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@70e27536
   [druid] 2018-12-07 17:53:37,827 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3c04c0e4
   [druid] 2018-12-07 17:53:37,838 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:53:37,840 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1002815220_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:53:37,864 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1002815220_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 17:53:37,868 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1002815220_0001_m_000000_0
   [druid] 2018-12-07 17:53:37,870 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 17:53:37,871 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:53:37,872 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:53:37,872 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:53:37,897 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:53:37,897 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:53:37,898 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:53:37,899 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 17:53:37,900 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:53:37,900 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:53:37,902 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 17:53:37,903 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:53:37,915 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:53:37,919 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1002815220_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:53:37,920 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:53:37,920 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1002815220_0001_r_000000_0' done.
   [druid] 2018-12-07 17:53:37,920 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1002815220_0001_r_000000_0
   [druid] 2018-12-07 17:53:37,921 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:53:37,925 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:53:38,444 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:53:38,444 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1002815220_0001 completed successfully
   [druid] 2018-12-07 17:53:38,455 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=610126
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=50
		Total committed heap usage (bytes)=687865856
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:54:46,227 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:54:46,228 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:54:46,801 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:54:46,881 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:54:46,909 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:54:46,972 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1417652569_0001
   [druid] 2018-12-07 17:54:47,093 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:54:47,094 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1417652569_0001
   [druid] 2018-12-07 17:54:47,095 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:54:47,100 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:54:47,100 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:54:47,106 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:54:47,141 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:54:47,142 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1417652569_0001_m_000000_0
   [druid] 2018-12-07 17:54:47,163 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:54:47,167 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:54:47,236 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3c6b45a2
   [druid] 2018-12-07 17:54:47,243 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 17:54:47,288 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:54:47,288 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:54:47,288 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:54:47,288 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:54:47,288 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:54:47,291 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:54:48,096 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1417652569_0001 running in uber mode : false
   [druid] 2018-12-07 17:54:48,097 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:54:53,173 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:54:54,113 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 50% reduce 0%
   [druid] 2018-12-07 17:54:55,704 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 17:54:55,705 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:54:55,705 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 17:54:55,705 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 362; bufvoid = 104857600
   [druid] 2018-12-07 17:54:55,705 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2018-12-07 17:54:55,732 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 17:54:55,738 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1417652569_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:54:55,739 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:54:55,740 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1417652569_0001_m_000000_0' done.
   [druid] 2018-12-07 17:54:55,740 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1417652569_0001_m_000000_0
   [druid] 2018-12-07 17:54:55,740 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:54:55,741 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:54:55,742 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1417652569_0001_r_000000_0
   [druid] 2018-12-07 17:54:55,747 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:54:55,747 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:54:55,820 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@44f0ba69
   [druid] 2018-12-07 17:54:55,823 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3ec19727
   [druid] 2018-12-07 17:54:55,834 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:54:55,836 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1417652569_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:54:55,861 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1417652569_0001_m_000000_0 decomp: 368 len: 372 to MEMORY
   [druid] 2018-12-07 17:54:55,865 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 368 bytes from map-output for attempt_local1417652569_0001_m_000000_0
   [druid] 2018-12-07 17:54:55,867 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 368, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->368
   [druid] 2018-12-07 17:54:55,868 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:54:55,869 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:54:55,869 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:54:55,878 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:54:55,878 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 17:54:55,880 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 368 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:54:55,880 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 372 bytes from disk
   [druid] 2018-12-07 17:54:55,881 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:54:55,881 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:54:55,881 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 17:54:55,882 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:54:55,891 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:54:55,971 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1417652569_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:54:55,972 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:54:55,972 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1417652569_0001_r_000000_0' done.
   [druid] 2018-12-07 17:54:55,972 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1417652569_0001_r_000000_0
   [druid] 2018-12-07 17:54:55,972 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:54:55,977 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:54:56,114 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:54:56,114 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1417652569_0001 completed successfully
   [druid] 2018-12-07 17:54:56,125 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1096
		FILE: Number of bytes written=611224
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=2
		Map output bytes=362
		Map output materialized bytes=372
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=372
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=51
		Total committed heap usage (bytes)=696254464
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:56:03,141 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:56:03,143 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:56:03,713 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:56:03,783 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:56:03,810 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:56:03,887 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1427090985_0001
   [druid] 2018-12-07 17:56:04,003 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:56:04,004 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1427090985_0001
   [druid] 2018-12-07 17:56:04,005 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:56:04,009 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:56:04,009 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:56:04,014 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:56:04,042 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:56:04,043 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1427090985_0001_m_000000_0
   [druid] 2018-12-07 17:56:04,065 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:56:04,068 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:56:04,142 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6ad286
   [druid] 2018-12-07 17:56:04,149 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-07 17:56:04,195 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:56:04,195 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:56:04,195 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:56:04,195 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:56:04,195 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:56:04,199 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:56:05,006 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1427090985_0001 running in uber mode : false
   [druid] 2018-12-07 17:56:05,007 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:56:05,284 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-07 17:56:05,286 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:56:05,286 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 17:56:05,286 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 191; bufvoid = 104857600
   [druid] 2018-12-07 17:56:05,286 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-12-07 17:56:05,395 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 17:56:05,400 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1427090985_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:56:05,407 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:56:05,407 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1427090985_0001_m_000000_0' done.
   [druid] 2018-12-07 17:56:05,407 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1427090985_0001_m_000000_0
   [druid] 2018-12-07 17:56:05,407 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:56:05,409 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:56:05,409 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1427090985_0001_r_000000_0
   [druid] 2018-12-07 17:56:05,414 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:56:05,414 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:56:05,491 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2d5cd95c
   [druid] 2018-12-07 17:56:05,494 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2cff18b7
   [druid] 2018-12-07 17:56:05,507 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:56:05,509 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1427090985_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:56:05,544 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1427090985_0001_m_000000_0 decomp: 195 len: 199 to MEMORY
   [druid] 2018-12-07 17:56:05,548 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 195 bytes from map-output for attempt_local1427090985_0001_m_000000_0
   [druid] 2018-12-07 17:56:05,550 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 195, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->195
   [druid] 2018-12-07 17:56:05,551 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:56:05,551 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:56:05,552 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:56:05,561 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:56:05,561 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2018-12-07 17:56:05,563 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 195 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:56:05,564 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 199 bytes from disk
   [druid] 2018-12-07 17:56:05,565 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:56:05,565 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:56:05,566 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2018-12-07 17:56:05,566 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:56:05,579 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:56:05,647 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1427090985_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:56:05,648 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:56:05,648 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1427090985_0001_r_000000_0' done.
   [druid] 2018-12-07 17:56:05,648 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1427090985_0001_r_000000_0
   [druid] 2018-12-07 17:56:05,648 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:56:05,652 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:56:06,010 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:56:06,010 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1427090985_0001 completed successfully
   [druid] 2018-12-07 17:56:06,021 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=748
		FILE: Number of bytes written=610703
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=65
		Map output records=1
		Map output bytes=191
		Map output materialized bytes=199
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=199
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=636485632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27156
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:58:26,786 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:58:26,787 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:58:27,339 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:58:27,417 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:58:27,446 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:58:27,509 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local889114768_0001
   [druid] 2018-12-07 17:58:27,625 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:58:27,626 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local889114768_0001
   [druid] 2018-12-07 17:58:27,627 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:58:27,630 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:58:27,630 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:58:27,634 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:58:27,667 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:58:27,668 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local889114768_0001_m_000000_0
   [druid] 2018-12-07 17:58:27,689 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:58:27,693 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:58:27,762 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@337af943
   [druid] 2018-12-07 17:58:27,769 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-07 17:58:27,814 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:58:27,815 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:58:27,815 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:58:27,815 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:58:27,815 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:58:27,818 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:58:28,628 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local889114768_0001 running in uber mode : false
   [druid] 2018-12-07 17:58:28,629 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:58:28,895 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-07 17:58:28,897 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:58:28,897 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 17:58:28,897 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 7449; bufvoid = 104857600
   [druid] 2018-12-07 17:58:28,897 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214244(104856976); length = 153/6553600
   [druid] 2018-12-07 17:58:28,922 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 17:58:28,928 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local889114768_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:58:28,934 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:58:28,934 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local889114768_0001_m_000000_0' done.
   [druid] 2018-12-07 17:58:28,934 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local889114768_0001_m_000000_0
   [druid] 2018-12-07 17:58:28,934 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:58:28,937 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:58:28,937 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local889114768_0001_r_000000_0
   [druid] 2018-12-07 17:58:28,942 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:58:28,942 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:58:29,018 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4a3cef78
   [druid] 2018-12-07 17:58:29,021 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2529bda7
   [druid] 2018-12-07 17:58:29,032 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:58:29,035 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local889114768_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:58:29,065 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local889114768_0001_m_000000_0 decomp: 7529 len: 7533 to MEMORY
   [druid] 2018-12-07 17:58:29,069 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 7529 bytes from map-output for attempt_local889114768_0001_m_000000_0
   [druid] 2018-12-07 17:58:29,070 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 7529, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7529
   [druid] 2018-12-07 17:58:29,070 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:58:29,071 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:58:29,071 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:58:29,079 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:58:29,079 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7424 bytes
   [druid] 2018-12-07 17:58:29,081 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 7529 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:58:29,082 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 7533 bytes from disk
   [druid] 2018-12-07 17:58:29,083 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:58:29,083 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:58:29,084 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7424 bytes
   [druid] 2018-12-07 17:58:29,084 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:58:29,095 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:58:29,170 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local889114768_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:58:29,171 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:58:29,171 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local889114768_0001_r_000000_0' done.
   [druid] 2018-12-07 17:58:29,172 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local889114768_0001_r_000000_0
   [druid] 2018-12-07 17:58:29,172 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:58:29,177 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:58:29,630 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:58:29,630 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local889114768_0001 completed successfully
   [druid] 2018-12-07 17:58:29,641 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=15416
		FILE: Number of bytes written=629605
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=65
		Map output records=39
		Map output bytes=7449
		Map output materialized bytes=7533
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=7533
		Reduce input records=39
		Reduce output records=1
		Spilled Records=78
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=634388480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27156
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 17:58:57,989 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 17:58:57,990 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 17:58:58,603 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 17:58:58,673 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 17:58:58,701 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 17:58:58,762 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local865728994_0001
   [druid] 2018-12-07 17:58:58,873 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 17:58:58,874 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local865728994_0001
   [druid] 2018-12-07 17:58:58,875 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 17:58:58,880 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:58:58,880 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 17:58:58,885 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 17:58:58,912 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 17:58:58,913 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local865728994_0001_m_000000_0
   [druid] 2018-12-07 17:58:58,931 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:58:58,935 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:58:59,001 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@74c7b2a3
   [druid] 2018-12-07 17:58:59,007 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-07 17:58:59,051 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 17:58:59,051 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 17:58:59,051 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 17:58:59,052 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 17:58:59,052 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 17:58:59,055 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 17:58:59,876 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local865728994_0001 running in uber mode : false
   [druid] 2018-12-07 17:58:59,877 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 17:59:00,104 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-07 17:59:00,106 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 17:59:00,106 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 17:59:00,106 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 7449; bufvoid = 104857600
   [druid] 2018-12-07 17:59:00,106 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214244(104856976); length = 153/6553600
   [druid] 2018-12-07 17:59:00,117 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 17:59:00,122 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local865728994_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:59:00,130 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 17:59:00,130 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local865728994_0001_m_000000_0' done.
   [druid] 2018-12-07 17:59:00,130 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local865728994_0001_m_000000_0
   [druid] 2018-12-07 17:59:00,130 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 17:59:00,132 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 17:59:00,132 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local865728994_0001_r_000000_0
   [druid] 2018-12-07 17:59:00,137 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 17:59:00,137 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 17:59:00,211 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@395926e9
   [druid] 2018-12-07 17:59:00,213 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@351c98a6
   [druid] 2018-12-07 17:59:00,224 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 17:59:00,226 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local865728994_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 17:59:00,251 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local865728994_0001_m_000000_0 decomp: 7529 len: 7533 to MEMORY
   [druid] 2018-12-07 17:59:00,255 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 7529 bytes from map-output for attempt_local865728994_0001_m_000000_0
   [druid] 2018-12-07 17:59:00,256 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 7529, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7529
   [druid] 2018-12-07 17:59:00,257 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 17:59:00,258 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:59:00,258 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 17:59:00,356 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:59:00,357 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7424 bytes
   [druid] 2018-12-07 17:59:00,359 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 7529 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 17:59:00,360 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 7533 bytes from disk
   [druid] 2018-12-07 17:59:00,360 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 17:59:00,360 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 17:59:00,361 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7424 bytes
   [druid] 2018-12-07 17:59:00,361 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 17:59:00,375 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 17:59:00,441 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local865728994_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 17:59:00,442 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 17:59:00,442 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local865728994_0001_r_000000_0' done.
   [druid] 2018-12-07 17:59:00,442 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local865728994_0001_r_000000_0
   [druid] 2018-12-07 17:59:00,442 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 17:59:00,447 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 17:59:00,879 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 17:59:00,879 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local865728994_0001 completed successfully
   [druid] 2018-12-07 17:59:00,890 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=15416
		FILE: Number of bytes written=629605
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=65
		Map output records=39
		Map output bytes=7449
		Map output materialized bytes=7533
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=7533
		Reduce input records=39
		Reduce output records=1
		Spilled Records=78
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=634388480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27156
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:07:24,446 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:07:24,447 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:07:25,058 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:07:25,135 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:07:25,167 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:07:25,232 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local837835315_0001
   [druid] 2018-12-07 18:07:25,352 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:07:25,353 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local837835315_0001
   [druid] 2018-12-07 18:07:25,354 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:07:25,359 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:07:25,359 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:07:25,363 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:07:25,395 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:07:25,397 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local837835315_0001_m_000000_0
   [druid] 2018-12-07 18:07:25,419 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:07:25,423 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:07:25,562 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@71727f7
   [druid] 2018-12-07 18:07:25,569 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-07 18:07:25,616 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:07:25,616 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:07:25,616 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:07:25,616 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:07:25,616 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:07:25,619 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:07:26,355 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local837835315_0001 running in uber mode : false
   [druid] 2018-12-07 18:07:26,356 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 18:07:26,657 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-07 18:07:26,659 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:07:26,659 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 18:07:26,659 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 7449; bufvoid = 104857600
   [druid] 2018-12-07 18:07:26,659 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214244(104856976); length = 153/6553600
   [druid] 2018-12-07 18:07:26,695 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 18:07:26,701 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local837835315_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:07:26,709 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:07:26,709 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local837835315_0001_m_000000_0' done.
   [druid] 2018-12-07 18:07:26,709 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local837835315_0001_m_000000_0
   [druid] 2018-12-07 18:07:26,710 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:07:26,711 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:07:26,711 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local837835315_0001_r_000000_0
   [druid] 2018-12-07 18:07:26,717 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:07:26,717 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:07:26,797 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1d7ce643
   [druid] 2018-12-07 18:07:26,800 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@328bbb9f
   [druid] 2018-12-07 18:07:26,814 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:07:26,816 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local837835315_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:07:26,845 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local837835315_0001_m_000000_0 decomp: 7529 len: 7533 to MEMORY
   [druid] 2018-12-07 18:07:26,851 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 7529 bytes from map-output for attempt_local837835315_0001_m_000000_0
   [druid] 2018-12-07 18:07:26,852 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 7529, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7529
   [druid] 2018-12-07 18:07:26,853 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:07:26,853 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:07:26,853 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:07:26,883 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:07:26,883 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7424 bytes
   [druid] 2018-12-07 18:07:26,886 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 7529 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:07:26,887 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 7533 bytes from disk
   [druid] 2018-12-07 18:07:26,887 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:07:26,887 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:07:26,888 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7424 bytes
   [druid] 2018-12-07 18:07:26,888 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:07:26,902 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:07:26,957 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local837835315_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:07:26,958 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:07:26,958 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local837835315_0001_r_000000_0' done.
   [druid] 2018-12-07 18:07:26,958 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local837835315_0001_r_000000_0
   [druid] 2018-12-07 18:07:26,958 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:07:26,964 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:07:27,358 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:07:27,358 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local837835315_0001 completed successfully
   [druid] 2018-12-07 18:07:27,369 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=15416
		FILE: Number of bytes written=629605
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=65
		Map output records=39
		Map output bytes=7449
		Map output materialized bytes=7533
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=7533
		Reduce input records=39
		Reduce output records=1
		Spilled Records=78
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=633339904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27156
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:08:57,552 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:08:57,554 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:08:58,153 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:08:58,216 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:08:58,243 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:08:58,308 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local22280326_0001
   [druid] 2018-12-07 18:08:58,434 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:08:58,435 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local22280326_0001
   [druid] 2018-12-07 18:08:58,436 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:08:58,441 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:08:58,441 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:08:58,445 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:08:58,478 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:08:58,479 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local22280326_0001_m_000000_0
   [druid] 2018-12-07 18:08:58,503 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:08:58,507 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:08:58,582 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@611c21b3
   [druid] 2018-12-07 18:08:58,588 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-07 18:08:58,634 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:08:58,635 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:08:58,635 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:08:58,635 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:08:58,635 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:08:58,638 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:08:59,437 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local22280326_0001 running in uber mode : false
   [druid] 2018-12-07 18:08:59,438 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 18:08:59,750 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-07 18:08:59,751 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:08:59,751 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 18:08:59,751 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 7449; bufvoid = 104857600
   [druid] 2018-12-07 18:08:59,751 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214244(104856976); length = 153/6553600
   [druid] 2018-12-07 18:08:59,860 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 18:08:59,866 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local22280326_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:08:59,873 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:08:59,873 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local22280326_0001_m_000000_0' done.
   [druid] 2018-12-07 18:08:59,873 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local22280326_0001_m_000000_0
   [druid] 2018-12-07 18:08:59,873 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:08:59,875 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:08:59,875 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local22280326_0001_r_000000_0
   [druid] 2018-12-07 18:08:59,881 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:08:59,881 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:08:59,959 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2f80c253
   [druid] 2018-12-07 18:08:59,962 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7c720da9
   [druid] 2018-12-07 18:08:59,976 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:08:59,978 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local22280326_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:09:00,019 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local22280326_0001_m_000000_0 decomp: 7529 len: 7533 to MEMORY
   [druid] 2018-12-07 18:09:00,025 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 7529 bytes from map-output for attempt_local22280326_0001_m_000000_0
   [druid] 2018-12-07 18:09:00,027 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 7529, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7529
   [druid] 2018-12-07 18:09:00,028 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:09:00,028 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:09:00,029 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:09:00,039 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:09:00,039 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7424 bytes
   [druid] 2018-12-07 18:09:00,042 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 7529 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:09:00,043 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 7533 bytes from disk
   [druid] 2018-12-07 18:09:00,043 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:09:00,043 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:09:00,044 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 7424 bytes
   [druid] 2018-12-07 18:09:00,044 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:09:00,057 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:09:00,096 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local22280326_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:09:00,097 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:09:00,097 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local22280326_0001_r_000000_0' done.
   [druid] 2018-12-07 18:09:00,097 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local22280326_0001_r_000000_0
   [druid] 2018-12-07 18:09:00,097 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:09:00,102 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:09:00,440 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:09:00,440 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local22280326_0001 completed successfully
   [druid] 2018-12-07 18:09:00,451 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=15416
		FILE: Number of bytes written=626505
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=65
		Map output records=39
		Map output bytes=7449
		Map output materialized bytes=7533
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=7533
		Reduce input records=39
		Reduce output records=1
		Spilled Records=78
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=634388480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27156
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:09:25,029 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:09:25,030 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:09:25,615 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:09:25,680 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:09:25,708 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:09:25,775 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local738200205_0001
   [druid] 2018-12-07 18:09:25,894 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:09:25,895 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local738200205_0001
   [druid] 2018-12-07 18:09:25,896 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:09:25,901 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:09:25,901 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:09:25,905 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:09:25,935 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:09:25,937 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local738200205_0001_m_000000_0
   [druid] 2018-12-07 18:09:25,958 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:09:25,961 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:09:26,033 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@109a569c
   [druid] 2018-12-07 18:09:26,040 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-07 18:09:26,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:09:26,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:09:26,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:09:26,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:09:26,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:09:26,090 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:09:26,897 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local738200205_0001 running in uber mode : false
   [druid] 2018-12-07 18:09:26,898 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 18:09:27,291 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-07 18:09:27,292 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:09:27,292 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 18:09:27,292 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 191; bufvoid = 104857600
   [druid] 2018-12-07 18:09:27,292 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
   [druid] 2018-12-07 18:09:27,404 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 18:09:27,410 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local738200205_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:09:27,417 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:09:27,417 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local738200205_0001_m_000000_0' done.
   [druid] 2018-12-07 18:09:27,417 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local738200205_0001_m_000000_0
   [druid] 2018-12-07 18:09:27,418 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:09:27,419 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:09:27,420 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local738200205_0001_r_000000_0
   [druid] 2018-12-07 18:09:27,426 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:09:27,426 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:09:27,509 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@75d0de51
   [druid] 2018-12-07 18:09:27,512 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1d3bdc67
   [druid] 2018-12-07 18:09:27,525 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:09:27,527 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local738200205_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:09:27,554 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local738200205_0001_m_000000_0 decomp: 195 len: 199 to MEMORY
   [druid] 2018-12-07 18:09:27,558 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 195 bytes from map-output for attempt_local738200205_0001_m_000000_0
   [druid] 2018-12-07 18:09:27,560 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 195, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->195
   [druid] 2018-12-07 18:09:27,561 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:09:27,562 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:09:27,562 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:09:27,571 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:09:27,571 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2018-12-07 18:09:27,573 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 195 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:09:27,574 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 199 bytes from disk
   [druid] 2018-12-07 18:09:27,574 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:09:27,574 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:09:27,575 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2018-12-07 18:09:27,575 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:09:27,586 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:09:27,623 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local738200205_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:09:27,623 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:09:27,623 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local738200205_0001_r_000000_0' done.
   [druid] 2018-12-07 18:09:27,624 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local738200205_0001_r_000000_0
   [druid] 2018-12-07 18:09:27,624 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:09:27,628 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:09:27,901 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:09:27,901 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local738200205_0001 completed successfully
   [druid] 2018-12-07 18:09:27,913 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=748
		FILE: Number of bytes written=607603
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=65
		Map output records=1
		Map output bytes=191
		Map output materialized bytes=199
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=199
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=634388480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27156
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:10:27,119 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:10:27,120 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:10:27,745 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:10:27,822 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:10:27,849 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:10:27,969 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local32993657_0001
   [druid] 2018-12-07 18:10:28,088 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:10:28,089 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local32993657_0001
   [druid] 2018-12-07 18:10:28,090 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:10:28,094 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:10:28,094 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:10:28,100 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:10:28,131 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:10:28,133 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local32993657_0001_m_000000_0
   [druid] 2018-12-07 18:10:28,153 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:10:28,157 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:10:28,227 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@d453466
   [druid] 2018-12-07 18:10:28,235 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 18:10:28,282 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:10:28,282 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:10:28,282 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:10:28,282 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:10:28,282 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:10:28,286 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:10:29,091 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local32993657_0001 running in uber mode : false
   [druid] 2018-12-07 18:10:29,092 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 18:10:34,163 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:10:35,096 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 51% reduce 0%
   [druid] 2018-12-07 18:10:36,323 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:10:36,324 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:10:36,324 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 18:10:36,324 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 362; bufvoid = 104857600
   [druid] 2018-12-07 18:10:36,324 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2018-12-07 18:10:36,336 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 18:10:36,438 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local32993657_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:10:36,440 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:10:36,440 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local32993657_0001_m_000000_0' done.
   [druid] 2018-12-07 18:10:36,440 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local32993657_0001_m_000000_0
   [druid] 2018-12-07 18:10:36,440 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:10:36,442 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:10:36,443 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local32993657_0001_r_000000_0
   [druid] 2018-12-07 18:10:36,452 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:10:36,452 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:10:36,540 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2007082c
   [druid] 2018-12-07 18:10:36,544 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3db3e162
   [druid] 2018-12-07 18:10:36,557 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:10:36,559 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local32993657_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:10:36,589 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local32993657_0001_m_000000_0 decomp: 368 len: 372 to MEMORY
   [druid] 2018-12-07 18:10:36,594 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 368 bytes from map-output for attempt_local32993657_0001_m_000000_0
   [druid] 2018-12-07 18:10:36,595 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 368, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->368
   [druid] 2018-12-07 18:10:36,596 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:10:36,597 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:10:36,597 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:10:36,605 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:10:36,605 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 18:10:36,607 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 368 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:10:36,609 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 372 bytes from disk
   [druid] 2018-12-07 18:10:36,610 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:10:36,610 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:10:36,610 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 18:10:36,611 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:10:36,619 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:10:36,666 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local32993657_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:10:36,667 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:10:36,667 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local32993657_0001_r_000000_0' done.
   [druid] 2018-12-07 18:10:36,667 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local32993657_0001_r_000000_0
   [druid] 2018-12-07 18:10:36,667 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:10:36,672 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:10:37,097 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:10:37,097 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local32993657_0001 completed successfully
   [druid] 2018-12-07 18:10:37,108 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1096
		FILE: Number of bytes written=605024
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=2
		Map output bytes=362
		Map output materialized bytes=372
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=372
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=51
		Total committed heap usage (bytes)=685768704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:14:25,130 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:14:25,131 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:14:25,703 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:14:25,773 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:14:25,799 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:14:25,857 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1625034853_0001
   [druid] 2018-12-07 18:14:25,976 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:14:25,976 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1625034853_0001
   [druid] 2018-12-07 18:14:25,977 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:14:25,982 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:14:25,983 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:14:25,988 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:14:26,016 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:14:26,017 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1625034853_0001_m_000000_0
   [druid] 2018-12-07 18:14:26,040 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:14:26,043 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:14:26,116 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@d453466
   [druid] 2018-12-07 18:14:26,123 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 18:14:26,168 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:14:26,168 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:14:26,168 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:14:26,168 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:14:26,168 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:14:26,171 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:14:26,978 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1625034853_0001 running in uber mode : false
   [druid] 2018-12-07 18:14:26,979 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 18:14:32,050 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:14:32,983 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 51% reduce 0%
   [druid] 2018-12-07 18:14:34,378 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:14:34,379 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:14:34,488 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1625034853_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:14:34,489 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:14:34,490 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1625034853_0001_m_000000_0' done.
   [druid] 2018-12-07 18:14:34,490 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1625034853_0001_m_000000_0
   [druid] 2018-12-07 18:14:34,490 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:14:34,492 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:14:34,492 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1625034853_0001_r_000000_0
   [druid] 2018-12-07 18:14:34,498 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:14:34,499 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:14:34,579 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@a5f0972
   [druid] 2018-12-07 18:14:34,582 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@22b86c8
   [druid] 2018-12-07 18:14:34,596 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:14:34,600 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1625034853_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:14:34,629 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1625034853_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 18:14:34,634 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1625034853_0001_m_000000_0
   [druid] 2018-12-07 18:14:34,635 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 18:14:34,636 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:14:34,637 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:14:34,637 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:14:34,648 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:14:34,648 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 18:14:34,650 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:14:34,651 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 18:14:34,652 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:14:34,652 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:14:34,654 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 18:14:34,654 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:14:34,668 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:14:34,672 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1625034853_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:14:34,672 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:14:34,673 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1625034853_0001_r_000000_0' done.
   [druid] 2018-12-07 18:14:34,673 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1625034853_0001_r_000000_0
   [druid] 2018-12-07 18:14:34,673 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:14:34,678 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:14:34,984 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:14:34,984 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1625034853_0001 completed successfully
   [druid] 2018-12-07 18:14:34,996 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=610126
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=54
		Total committed heap usage (bytes)=686817280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:21:05,141 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:21:05,142 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:21:05,689 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:21:05,752 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:21:05,776 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:21:05,834 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local882486443_0001
   [druid] 2018-12-07 18:21:05,947 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:21:05,947 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local882486443_0001
   [druid] 2018-12-07 18:21:05,948 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:21:05,952 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:21:05,952 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:21:05,956 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:21:05,981 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:21:05,982 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local882486443_0001_m_000000_0
   [druid] 2018-12-07 18:21:06,003 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:21:06,007 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:21:06,075 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7f34b09c
   [druid] 2018-12-07 18:21:06,081 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 18:21:06,125 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:21:06,126 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:21:06,126 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:21:06,126 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:21:06,126 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:21:06,128 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:21:06,613 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-07 18:21:06,615 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:21:06,615 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 18:21:06,615 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 30644; bufvoid = 104857600
   [druid] 2018-12-07 18:21:06,615 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26213456(104853824); length = 941/6553600
   [druid] 2018-12-07 18:21:06,726 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 18:21:06,731 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local882486443_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:21:06,738 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:21:06,739 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local882486443_0001_m_000000_0' done.
   [druid] 2018-12-07 18:21:06,739 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local882486443_0001_m_000000_0
   [druid] 2018-12-07 18:21:06,739 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:21:06,741 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:21:06,741 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local882486443_0001_r_000000_0
   [druid] 2018-12-07 18:21:06,746 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:21:06,746 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:21:06,817 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1d9f87a9
   [druid] 2018-12-07 18:21:06,820 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3da0e165
   [druid] 2018-12-07 18:21:06,831 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:21:06,834 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local882486443_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:21:06,862 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local882486443_0001_m_000000_0 decomp: 31118 len: 31122 to MEMORY
   [druid] 2018-12-07 18:21:06,867 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 31118 bytes from map-output for attempt_local882486443_0001_m_000000_0
   [druid] 2018-12-07 18:21:06,869 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 31118, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->31118
   [druid] 2018-12-07 18:21:06,870 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:21:06,870 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:21:06,871 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:21:06,881 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:21:06,882 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 31044 bytes
   [druid] 2018-12-07 18:21:06,885 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 31118 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:21:06,886 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 31122 bytes from disk
   [druid] 2018-12-07 18:21:06,886 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:21:06,886 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:21:06,887 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 31044 bytes
   [druid] 2018-12-07 18:21:06,887 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:21:06,949 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local882486443_0001 running in uber mode : false
   [druid] 2018-12-07 18:21:06,950 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-12-07 18:21:07,130 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:21:07,369 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local882486443_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:21:07,369 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:21:07,369 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local882486443_0001_r_000000_0' done.
   [druid] 2018-12-07 18:21:07,370 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local882486443_0001_r_000000_0
   [druid] 2018-12-07 18:21:07,370 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:21:07,374 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:21:07,952 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:21:07,952 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local882486443_0001 completed successfully
   [druid] 2018-12-07 18:21:07,962 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=62596
		FILE: Number of bytes written=699974
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=236
		Map output bytes=30644
		Map output materialized bytes=31122
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=31122
		Reduce input records=236
		Reduce output records=7
		Spilled Records=472
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=633339904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:21:20,994 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:21:20,996 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:21:21,539 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:21:21,605 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:21:21,632 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:21:21,692 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local821869571_0001
   [druid] 2018-12-07 18:21:21,808 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:21:21,808 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local821869571_0001
   [druid] 2018-12-07 18:21:21,809 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:21:21,813 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:21:21,813 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:21:21,818 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:21:21,845 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:21:21,846 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local821869571_0001_m_000000_0
   [druid] 2018-12-07 18:21:21,864 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:21:21,868 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:21:21,938 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5a48181a
   [druid] 2018-12-07 18:21:21,945 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 18:21:21,990 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:21:21,990 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:21:21,991 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:21:21,991 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:21:21,991 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:21:21,993 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:21:22,412 [ask Executor #0] INFO  ce.ActiveUser.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-07 18:21:22,413 [ask Executor #0] INFO  ce.ActiveUser.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-07 18:21:22,413 [ask Executor #0] INFO  ce.ActiveUser.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-07 18:21:22,413 [ask Executor #0] INFO  ce.ActiveUser.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-07 18:21:22,413 [ask Executor #0] INFO  ce.ActiveUser.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-07 18:21:22,414 [ask Executor #0] INFO  ce.ActiveUser.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-07 18:21:22,414 [ask Executor #0] INFO  ce.ActiveUser.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-07 18:21:22,414 [ask Executor #0] INFO  ce.ActiveUser.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-07 18:21:22,414 [ask Executor #0] INFO  ce.ActiveUser.ActiveUserMapper {1} - serverTime或者uuid不能为空
   [druid] 2018-12-07 18:21:22,523 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-07 18:21:22,525 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:21:22,525 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 18:21:22,525 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 417162; bufvoid = 104857600
   [druid] 2018-12-07 18:21:22,525 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26201752(104807008); length = 12645/6553600
   [druid] 2018-12-07 18:21:22,566 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 18:21:22,573 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local821869571_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:21:22,581 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:21:22,581 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local821869571_0001_m_000000_0' done.
   [druid] 2018-12-07 18:21:22,582 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local821869571_0001_m_000000_0
   [druid] 2018-12-07 18:21:22,582 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:21:22,583 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:21:22,584 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local821869571_0001_r_000000_0
   [druid] 2018-12-07 18:21:22,589 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:21:22,589 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:21:22,660 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2274bc9e
   [druid] 2018-12-07 18:21:22,663 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68e30d36
   [druid] 2018-12-07 18:21:22,673 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:21:22,675 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local821869571_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:21:22,703 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local821869571_0001_m_000000_0 decomp: 423488 len: 423492 to MEMORY
   [druid] 2018-12-07 18:21:22,710 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 423488 bytes from map-output for attempt_local821869571_0001_m_000000_0
   [druid] 2018-12-07 18:21:22,711 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 423488, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->423488
   [druid] 2018-12-07 18:21:22,712 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:21:22,713 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:21:22,713 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:21:22,722 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:21:22,722 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 423414 bytes
   [druid] 2018-12-07 18:21:22,810 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local821869571_0001 running in uber mode : false
   [druid] 2018-12-07 18:21:22,811 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-12-07 18:21:22,814 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 423488 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:21:22,815 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 423492 bytes from disk
   [druid] 2018-12-07 18:21:22,816 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:21:22,816 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:21:22,817 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 423414 bytes
   [druid] 2018-12-07 18:21:22,817 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:21:23,056 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:21:23,416 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local821869571_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:21:23,417 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:21:23,417 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local821869571_0001_r_000000_0' done.
   [druid] 2018-12-07 18:21:23,417 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local821869571_0001_r_000000_0
   [druid] 2018-12-07 18:21:23,417 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:21:23,422 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:21:23,811 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:21:23,811 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local821869571_0001 completed successfully
   [druid] 2018-12-07 18:21:23,822 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=847336
		FILE: Number of bytes written=1877144
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=3162
		Map output bytes=417162
		Map output materialized bytes=423492
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=423492
		Reduce input records=3162
		Reduce output records=14
		Spilled Records=6324
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:21:37,003 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:21:37,004 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:21:37,552 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:21:37,627 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:21:37,653 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:21:37,718 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local24877354_0001
   [druid] 2018-12-07 18:21:37,829 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:21:37,830 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local24877354_0001
   [druid] 2018-12-07 18:21:37,831 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:21:37,834 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:21:37,835 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:21:37,839 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:21:37,868 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:21:37,870 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local24877354_0001_m_000000_0
   [druid] 2018-12-07 18:21:37,890 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:21:37,893 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:21:37,962 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@77802544
   [druid] 2018-12-07 18:21:37,969 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 18:21:38,016 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:21:38,016 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:21:38,016 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:21:38,016 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:21:38,016 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:21:38,019 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:21:38,430 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 18:21:38,431 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 18:21:38,431 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 18:21:38,432 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 18:21:38,432 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 18:21:38,432 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 18:21:38,432 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 18:21:38,432 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 18:21:38,433 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-07 18:21:38,831 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local24877354_0001 running in uber mode : false
   [druid] 2018-12-07 18:21:38,831 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 18:21:43,897 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:21:44,837 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 28% reduce 0%
   [druid] 2018-12-07 18:21:46,898 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:21:47,838 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 46% reduce 0%
   [druid] 2018-12-07 18:21:49,899 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:21:50,566 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:21:50,568 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:21:50,568 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 18:21:50,568 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1006; bufvoid = 104857600
   [druid] 2018-12-07 18:21:50,568 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
   [druid] 2018-12-07 18:21:50,577 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 18:21:50,676 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local24877354_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:21:50,677 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:21:50,677 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local24877354_0001_m_000000_0' done.
   [druid] 2018-12-07 18:21:50,678 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local24877354_0001_m_000000_0
   [druid] 2018-12-07 18:21:50,678 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:21:50,680 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:21:50,680 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local24877354_0001_r_000000_0
   [druid] 2018-12-07 18:21:50,686 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:21:50,686 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:21:50,764 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1a7febab
   [druid] 2018-12-07 18:21:50,767 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@9b643bd
   [druid] 2018-12-07 18:21:50,778 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:21:50,780 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local24877354_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:21:50,808 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local24877354_0001_m_000000_0 decomp: 1024 len: 1028 to MEMORY
   [druid] 2018-12-07 18:21:50,813 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1024 bytes from map-output for attempt_local24877354_0001_m_000000_0
   [druid] 2018-12-07 18:21:50,814 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1024, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1024
   [druid] 2018-12-07 18:21:50,816 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:21:50,816 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:21:50,816 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:21:50,825 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:21:50,825 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 944 bytes
   [druid] 2018-12-07 18:21:50,827 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 1024 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:21:50,827 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 1028 bytes from disk
   [druid] 2018-12-07 18:21:50,828 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:21:50,828 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:21:50,829 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 944 bytes
   [druid] 2018-12-07 18:21:50,829 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:21:50,845 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:21:50,887 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-12-07 18:21:50,913 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local24877354_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:21:50,914 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:21:50,914 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local24877354_0001_r_000000_0' done.
   [druid] 2018-12-07 18:21:50,914 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local24877354_0001_r_000000_0
   [druid] 2018-12-07 18:21:50,914 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:21:50,918 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:21:51,887 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:21:51,887 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local24877354_0001 completed successfully
   [druid] 2018-12-07 18:21:51,898 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=2408
		FILE: Number of bytes written=606632
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=8
		Map output bytes=1006
		Map output materialized bytes=1028
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=1028
		Reduce input records=8
		Reduce output records=3
		Spilled Records=16
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=118
		Total committed heap usage (bytes)=784334848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:22:23,513 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:22:23,514 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:22:24,058 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:22:24,127 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:22:24,153 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:22:24,218 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1222501744_0001
   [druid] 2018-12-07 18:22:24,330 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:22:24,330 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1222501744_0001
   [druid] 2018-12-07 18:22:24,331 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:22:24,335 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:22:24,335 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:22:24,339 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:22:24,364 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:22:24,366 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1222501744_0001_m_000000_0
   [druid] 2018-12-07 18:22:24,385 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:22:24,389 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:22:24,462 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7977cd1f
   [druid] 2018-12-07 18:22:24,468 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 18:22:24,513 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:22:24,513 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:22:24,513 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:22:24,513 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:22:24,513 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:22:24,516 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:22:25,333 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1222501744_0001 running in uber mode : false
   [druid] 2018-12-07 18:22:25,335 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 18:22:30,398 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:22:31,340 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 50% reduce 0%
   [druid] 2018-12-07 18:22:32,931 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:22:32,933 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:22:33,044 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1222501744_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:22:33,045 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:22:33,045 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1222501744_0001_m_000000_0' done.
   [druid] 2018-12-07 18:22:33,045 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1222501744_0001_m_000000_0
   [druid] 2018-12-07 18:22:33,046 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:22:33,047 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:22:33,048 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1222501744_0001_r_000000_0
   [druid] 2018-12-07 18:22:33,054 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:22:33,055 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:22:33,125 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6fc9874
   [druid] 2018-12-07 18:22:33,128 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42c54c4a
   [druid] 2018-12-07 18:22:33,140 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:22:33,142 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1222501744_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:22:33,171 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1222501744_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 18:22:33,176 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1222501744_0001_m_000000_0
   [druid] 2018-12-07 18:22:33,178 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 18:22:33,179 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:22:33,180 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:22:33,180 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:22:33,192 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:22:33,192 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 18:22:33,194 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:22:33,194 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 18:22:33,195 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:22:33,195 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:22:33,198 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 18:22:33,198 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:22:33,211 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:22:33,215 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1222501744_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:22:33,216 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:22:33,216 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1222501744_0001_r_000000_0' done.
   [druid] 2018-12-07 18:22:33,216 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1222501744_0001_r_000000_0
   [druid] 2018-12-07 18:22:33,216 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:22:33,222 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:22:33,340 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:22:33,340 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1222501744_0001 completed successfully
   [druid] 2018-12-07 18:22:33,353 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=610126
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=59
		Total committed heap usage (bytes)=686817280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:26:21,790 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:26:21,791 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:26:22,396 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:26:22,464 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:26:22,492 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:26:22,554 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1047567186_0001
   [druid] 2018-12-07 18:26:22,674 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:26:22,675 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1047567186_0001
   [druid] 2018-12-07 18:26:22,676 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:26:22,681 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:26:22,681 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:26:22,687 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:26:22,714 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:26:22,715 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1047567186_0001_m_000000_0
   [druid] 2018-12-07 18:26:22,733 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:26:22,736 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:26:22,807 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@73a1d23
   [druid] 2018-12-07 18:26:22,814 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 18:26:22,859 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:26:22,859 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:26:22,859 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:26:22,859 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:26:22,859 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:26:22,862 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:26:23,677 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1047567186_0001 running in uber mode : false
   [druid] 2018-12-07 18:26:23,678 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 18:26:28,746 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:26:29,681 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 49% reduce 0%
   [druid] 2018-12-07 18:26:31,681 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:26:31,683 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:26:31,710 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1047567186_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:26:31,712 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:26:31,712 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1047567186_0001_m_000000_0' done.
   [druid] 2018-12-07 18:26:31,712 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1047567186_0001_m_000000_0
   [druid] 2018-12-07 18:26:31,712 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:26:31,715 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:26:31,715 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1047567186_0001_r_000000_0
   [druid] 2018-12-07 18:26:31,721 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:26:31,722 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:26:31,804 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@265f9724
   [druid] 2018-12-07 18:26:31,807 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1a78eec5
   [druid] 2018-12-07 18:26:31,818 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:26:31,820 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1047567186_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:26:31,846 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1047567186_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 18:26:31,849 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1047567186_0001_m_000000_0
   [druid] 2018-12-07 18:26:31,850 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 18:26:31,851 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:26:31,852 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:26:31,852 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:26:31,861 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:26:31,861 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 18:26:31,863 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:26:31,864 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 18:26:31,864 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:26:31,864 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:26:31,866 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 18:26:31,866 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:26:31,877 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:26:31,880 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1047567186_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:26:31,881 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:26:31,881 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1047567186_0001_r_000000_0' done.
   [druid] 2018-12-07 18:26:31,881 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1047567186_0001_r_000000_0
   [druid] 2018-12-07 18:26:31,882 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:26:31,887 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:26:32,682 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:26:32,682 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1047567186_0001 completed successfully
   [druid] 2018-12-07 18:26:32,694 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=610126
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=53
		Total committed heap usage (bytes)=681574400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:28:03,776 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:28:03,777 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:28:04,335 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:28:04,402 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:28:04,430 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:28:04,488 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local571869316_0001
   [druid] 2018-12-07 18:28:04,597 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:28:04,598 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local571869316_0001
   [druid] 2018-12-07 18:28:04,599 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:28:04,604 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:28:04,604 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:28:04,610 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:28:04,638 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:28:04,639 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local571869316_0001_m_000000_0
   [druid] 2018-12-07 18:28:04,658 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:28:04,662 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:28:04,726 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@219664a3
   [druid] 2018-12-07 18:28:04,732 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 18:28:04,776 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:28:04,776 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:28:04,776 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:28:04,776 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:28:04,776 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:28:04,779 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:28:05,600 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local571869316_0001 running in uber mode : false
   [druid] 2018-12-07 18:28:05,601 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 18:28:10,672 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:28:11,605 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 49% reduce 0%
   [druid] 2018-12-07 18:28:13,674 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:28:13,709 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:28:13,711 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:28:13,852 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local571869316_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:28:13,854 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:28:13,854 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local571869316_0001_m_000000_0' done.
   [druid] 2018-12-07 18:28:13,854 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local571869316_0001_m_000000_0
   [druid] 2018-12-07 18:28:13,854 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:28:13,856 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:28:13,857 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local571869316_0001_r_000000_0
   [druid] 2018-12-07 18:28:13,862 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:28:13,862 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:28:13,941 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4947f36f
   [druid] 2018-12-07 18:28:13,944 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@15a6c028
   [druid] 2018-12-07 18:28:13,955 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:28:13,957 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local571869316_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:28:13,980 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local571869316_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 18:28:13,984 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local571869316_0001_m_000000_0
   [druid] 2018-12-07 18:28:13,985 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 18:28:13,987 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:28:13,987 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:28:13,988 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:28:13,996 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:28:13,997 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 18:28:13,998 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:28:13,999 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 18:28:14,000 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:28:14,000 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:28:14,002 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 18:28:14,002 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:28:14,011 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:28:14,015 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local571869316_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:28:14,015 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:28:14,015 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local571869316_0001_r_000000_0' done.
   [druid] 2018-12-07 18:28:14,015 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local571869316_0001_r_000000_0
   [druid] 2018-12-07 18:28:14,016 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:28:14,020 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:28:14,606 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:28:14,606 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local571869316_0001 completed successfully
   [druid] 2018-12-07 18:28:14,618 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=607026
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=60
		Total committed heap usage (bytes)=689963008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:30:31,666 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:30:31,668 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:30:32,204 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:30:32,275 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:30:32,302 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:30:32,364 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1999741703_0001
   [druid] 2018-12-07 18:30:32,477 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:30:32,478 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1999741703_0001
   [druid] 2018-12-07 18:30:32,479 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:30:32,485 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:30:32,485 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:30:32,491 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:30:32,518 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:30:32,519 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1999741703_0001_m_000000_0
   [druid] 2018-12-07 18:30:32,539 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:30:32,543 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:30:32,617 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@56ae32c0
   [druid] 2018-12-07 18:30:32,624 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 18:30:32,667 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:30:32,668 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:30:32,668 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:30:32,668 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:30:32,668 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:30:32,670 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:30:33,479 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1999741703_0001 running in uber mode : false
   [druid] 2018-12-07 18:30:33,480 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 18:30:38,550 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:30:39,483 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 48% reduce 0%
   [druid] 2018-12-07 18:30:41,488 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:30:41,490 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:30:41,490 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 18:30:41,490 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 362; bufvoid = 104857600
   [druid] 2018-12-07 18:30:41,490 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2018-12-07 18:30:41,500 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 18:30:41,550 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > sort
   [druid] 2018-12-07 18:30:41,595 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1999741703_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:30:41,596 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:30:41,596 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1999741703_0001_m_000000_0' done.
   [druid] 2018-12-07 18:30:41,597 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1999741703_0001_m_000000_0
   [druid] 2018-12-07 18:30:41,597 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:30:41,599 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:30:41,599 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1999741703_0001_r_000000_0
   [druid] 2018-12-07 18:30:41,607 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:30:41,608 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:30:41,695 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@57f5b74f
   [druid] 2018-12-07 18:30:41,698 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2324b3b1
   [druid] 2018-12-07 18:30:41,712 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:30:41,713 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1999741703_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:30:41,738 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1999741703_0001_m_000000_0 decomp: 368 len: 372 to MEMORY
   [druid] 2018-12-07 18:30:41,743 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 368 bytes from map-output for attempt_local1999741703_0001_m_000000_0
   [druid] 2018-12-07 18:30:41,744 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 368, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->368
   [druid] 2018-12-07 18:30:41,745 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:30:41,746 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:30:41,746 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:30:41,755 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:30:41,755 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 18:30:41,756 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 368 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:30:41,757 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 372 bytes from disk
   [druid] 2018-12-07 18:30:41,757 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:30:41,758 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:30:41,758 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 18:30:41,759 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:30:41,768 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:30:41,831 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1999741703_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:30:41,831 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:30:41,832 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1999741703_0001_r_000000_0' done.
   [druid] 2018-12-07 18:30:41,832 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1999741703_0001_r_000000_0
   [druid] 2018-12-07 18:30:41,832 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:30:41,838 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:30:42,484 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:30:42,484 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1999741703_0001 completed successfully
   [druid] 2018-12-07 18:30:42,496 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1096
		FILE: Number of bytes written=611224
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=2
		Map output bytes=362
		Map output materialized bytes=372
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=372
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=52
		Total committed heap usage (bytes)=685768704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:42:17,639 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:42:17,640 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:42:18,202 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:42:18,269 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:42:18,295 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:42:18,356 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1131330280_0001
   [druid] 2018-12-07 18:42:18,475 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:42:18,476 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1131330280_0001
   [druid] 2018-12-07 18:42:18,477 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:42:18,481 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:42:18,481 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:42:18,486 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:42:18,517 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:42:18,519 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1131330280_0001_m_000000_0
   [druid] 2018-12-07 18:42:18,536 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:42:18,540 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:42:18,682 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6105b3dc
   [druid] 2018-12-07 18:42:18,690 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 18:42:18,735 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:42:18,735 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:42:18,735 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:42:18,735 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:42:18,736 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:42:18,740 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:42:19,478 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1131330280_0001 running in uber mode : false
   [druid] 2018-12-07 18:42:19,479 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 18:42:24,548 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:42:25,482 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 47% reduce 0%
   [druid] 2018-12-07 18:42:27,549 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:42:27,811 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:42:27,812 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:42:27,812 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 18:42:27,812 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 362; bufvoid = 104857600
   [druid] 2018-12-07 18:42:27,812 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2018-12-07 18:42:27,912 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 18:42:27,922 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1131330280_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:42:27,924 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:42:27,924 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1131330280_0001_m_000000_0' done.
   [druid] 2018-12-07 18:42:27,925 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1131330280_0001_m_000000_0
   [druid] 2018-12-07 18:42:27,925 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:42:27,927 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:42:27,927 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1131330280_0001_r_000000_0
   [druid] 2018-12-07 18:42:27,934 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:42:27,934 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:42:28,017 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6e08b0dd
   [druid] 2018-12-07 18:42:28,020 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6a3d1c86
   [druid] 2018-12-07 18:42:28,030 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:42:28,032 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1131330280_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:42:28,056 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1131330280_0001_m_000000_0 decomp: 368 len: 372 to MEMORY
   [druid] 2018-12-07 18:42:28,059 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 368 bytes from map-output for attempt_local1131330280_0001_m_000000_0
   [druid] 2018-12-07 18:42:28,061 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 368, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->368
   [druid] 2018-12-07 18:42:28,062 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:42:28,063 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:42:28,063 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:42:28,071 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:42:28,071 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 18:42:28,073 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 368 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:42:28,074 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 372 bytes from disk
   [druid] 2018-12-07 18:42:28,074 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:42:28,074 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:42:28,075 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 18:42:28,075 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:42:28,085 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:42:28,137 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1131330280_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:42:28,138 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:42:28,138 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1131330280_0001_r_000000_0' done.
   [druid] 2018-12-07 18:42:28,138 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1131330280_0001_r_000000_0
   [druid] 2018-12-07 18:42:28,138 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:42:28,145 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:42:28,483 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:42:28,483 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1131330280_0001 completed successfully
   [druid] 2018-12-07 18:42:28,496 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1096
		FILE: Number of bytes written=611224
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=2
		Map output bytes=362
		Map output materialized bytes=372
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=372
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=57
		Total committed heap usage (bytes)=685768704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:46:02,789 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:46:02,790 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:46:03,352 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:46:03,423 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:46:03,452 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:46:03,582 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local127599282_0001
   [druid] 2018-12-07 18:46:03,695 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:46:03,696 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local127599282_0001
   [druid] 2018-12-07 18:46:03,697 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:46:03,701 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:46:03,701 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:46:03,706 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:46:03,734 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:46:03,735 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local127599282_0001_m_000000_0
   [druid] 2018-12-07 18:46:03,754 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:46:03,758 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:46:03,829 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7977cd1f
   [druid] 2018-12-07 18:46:03,836 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 18:46:03,881 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:46:03,881 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:46:03,881 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:46:03,881 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:46:03,881 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:46:03,884 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:46:04,698 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local127599282_0001 running in uber mode : false
   [druid] 2018-12-07 18:46:04,699 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 18:46:09,767 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:46:10,702 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 48% reduce 0%
   [druid] 2018-12-07 18:46:12,688 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:46:12,690 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:46:12,690 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 18:46:12,690 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 362; bufvoid = 104857600
   [druid] 2018-12-07 18:46:12,690 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2018-12-07 18:46:12,767 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > sort
   [druid] 2018-12-07 18:46:12,790 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 18:46:12,794 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local127599282_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:46:12,796 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:46:12,796 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local127599282_0001_m_000000_0' done.
   [druid] 2018-12-07 18:46:12,796 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local127599282_0001_m_000000_0
   [druid] 2018-12-07 18:46:12,796 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:46:12,797 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:46:12,798 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local127599282_0001_r_000000_0
   [druid] 2018-12-07 18:46:12,803 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:46:12,803 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:46:12,884 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@11acaf33
   [druid] 2018-12-07 18:46:12,887 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@28721c87
   [druid] 2018-12-07 18:46:12,901 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:46:12,903 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local127599282_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:46:12,933 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local127599282_0001_m_000000_0 decomp: 368 len: 372 to MEMORY
   [druid] 2018-12-07 18:46:12,936 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 368 bytes from map-output for attempt_local127599282_0001_m_000000_0
   [druid] 2018-12-07 18:46:12,938 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 368, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->368
   [druid] 2018-12-07 18:46:12,940 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:46:12,941 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:46:12,941 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:46:12,950 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:46:12,950 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 18:46:12,951 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 368 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:46:12,952 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 372 bytes from disk
   [druid] 2018-12-07 18:46:12,952 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:46:12,952 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:46:12,953 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 18:46:12,953 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:46:12,964 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:46:13,008 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local127599282_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:46:13,009 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:46:13,009 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local127599282_0001_r_000000_0' done.
   [druid] 2018-12-07 18:46:13,009 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local127599282_0001_r_000000_0
   [druid] 2018-12-07 18:46:13,009 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:46:13,014 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:46:13,703 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:46:13,703 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local127599282_0001 completed successfully
   [druid] 2018-12-07 18:46:13,715 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1096
		FILE: Number of bytes written=608124
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=2
		Map output bytes=362
		Map output materialized bytes=372
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=372
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=56
		Total committed heap usage (bytes)=684720128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 18:59:11,858 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 18:59:11,859 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 18:59:12,404 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 18:59:12,468 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 18:59:12,494 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 18:59:12,553 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1938842666_0001
   [druid] 2018-12-07 18:59:12,663 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 18:59:12,663 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1938842666_0001
   [druid] 2018-12-07 18:59:12,664 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 18:59:12,668 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:59:12,668 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 18:59:12,673 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 18:59:12,700 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 18:59:12,702 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1938842666_0001_m_000000_0
   [druid] 2018-12-07 18:59:12,721 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:59:12,725 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:59:12,793 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@17820f4
   [druid] 2018-12-07 18:59:12,801 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 18:59:12,846 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 18:59:12,846 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 18:59:12,846 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 18:59:12,846 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 18:59:12,847 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 18:59:12,849 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 18:59:13,665 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1938842666_0001 running in uber mode : false
   [druid] 2018-12-07 18:59:13,666 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 18:59:18,732 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:59:19,670 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 49% reduce 0%
   [druid] 2018-12-07 18:59:21,733 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:59:21,746 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 18:59:21,747 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 18:59:21,803 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1938842666_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:59:21,805 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 18:59:21,805 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1938842666_0001_m_000000_0' done.
   [druid] 2018-12-07 18:59:21,805 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1938842666_0001_m_000000_0
   [druid] 2018-12-07 18:59:21,806 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 18:59:21,808 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 18:59:21,809 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1938842666_0001_r_000000_0
   [druid] 2018-12-07 18:59:21,816 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 18:59:21,816 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 18:59:21,901 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@24ef2367
   [druid] 2018-12-07 18:59:21,904 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@28f63bbb
   [druid] 2018-12-07 18:59:21,916 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 18:59:21,918 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1938842666_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 18:59:21,943 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1938842666_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 18:59:21,947 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1938842666_0001_m_000000_0
   [druid] 2018-12-07 18:59:21,948 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 18:59:21,949 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 18:59:21,950 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:59:21,950 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 18:59:21,958 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:59:21,958 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 18:59:22,002 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 18:59:22,002 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 18:59:22,003 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 18:59:22,003 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 18:59:22,005 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 18:59:22,005 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 18:59:22,015 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 18:59:22,020 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1938842666_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 18:59:22,021 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 18:59:22,021 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1938842666_0001_r_000000_0' done.
   [druid] 2018-12-07 18:59:22,021 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1938842666_0001_r_000000_0
   [druid] 2018-12-07 18:59:22,021 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 18:59:22,026 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 18:59:22,671 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 18:59:22,671 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1938842666_0001 completed successfully
   [druid] 2018-12-07 18:59:22,683 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=610126
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=52
		Total committed heap usage (bytes)=684720128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 19:01:03,985 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 19:01:03,986 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 19:01:04,615 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 19:01:04,688 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 19:01:04,715 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 19:01:04,792 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local2013729899_0001
   [druid] 2018-12-07 19:01:04,910 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 19:01:04,910 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local2013729899_0001
   [druid] 2018-12-07 19:01:04,911 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 19:01:04,915 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 19:01:04,915 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 19:01:04,920 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 19:01:04,948 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 19:01:04,950 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2013729899_0001_m_000000_0
   [druid] 2018-12-07 19:01:04,970 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 19:01:04,974 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 19:01:05,046 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3c6b45a2
   [druid] 2018-12-07 19:01:05,053 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 19:01:05,098 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 19:01:05,098 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 19:01:05,098 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 19:01:05,098 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 19:01:05,098 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 19:01:05,101 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 19:01:05,912 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local2013729899_0001 running in uber mode : false
   [druid] 2018-12-07 19:01:05,913 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 19:01:10,980 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 19:01:11,938 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 51% reduce 0%
   [druid] 2018-12-07 19:01:13,338 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 19:01:13,340 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 19:01:13,444 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2013729899_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 19:01:13,445 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 19:01:13,445 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2013729899_0001_m_000000_0' done.
   [druid] 2018-12-07 19:01:13,446 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2013729899_0001_m_000000_0
   [druid] 2018-12-07 19:01:13,446 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 19:01:13,447 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 19:01:13,448 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2013729899_0001_r_000000_0
   [druid] 2018-12-07 19:01:13,454 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 19:01:13,454 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 19:01:13,535 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@a5f0972
   [druid] 2018-12-07 19:01:13,538 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@22b86c8
   [druid] 2018-12-07 19:01:13,549 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 19:01:13,552 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local2013729899_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 19:01:13,574 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local2013729899_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-07 19:01:13,578 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local2013729899_0001_m_000000_0
   [druid] 2018-12-07 19:01:13,579 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-07 19:01:13,579 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 19:01:13,580 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 19:01:13,580 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 19:01:13,589 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 19:01:13,589 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 19:01:13,590 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 19:01:13,591 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-07 19:01:13,591 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 19:01:13,591 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 19:01:13,593 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-07 19:01:13,594 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 19:01:13,603 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 19:01:13,606 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2013729899_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 19:01:13,607 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 19:01:13,607 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2013729899_0001_r_000000_0' done.
   [druid] 2018-12-07 19:01:13,607 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2013729899_0001_r_000000_0
   [druid] 2018-12-07 19:01:13,607 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 19:01:13,611 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 19:01:13,939 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 19:01:13,939 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local2013729899_0001 completed successfully
   [druid] 2018-12-07 19:01:13,949 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=610126
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=53
		Total committed heap usage (bytes)=685768704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 19:12:35,250 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 19:12:35,251 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 19:12:35,860 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 19:12:35,924 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 19:12:35,952 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 19:12:36,015 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1375436277_0001
   [druid] 2018-12-07 19:12:36,139 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 19:12:36,140 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1375436277_0001
   [druid] 2018-12-07 19:12:36,141 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 19:12:36,145 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 19:12:36,145 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 19:12:36,151 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 19:12:36,186 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 19:12:36,188 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1375436277_0001_m_000000_0
   [druid] 2018-12-07 19:12:36,207 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 19:12:36,210 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 19:12:36,346 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6105b3dc
   [druid] 2018-12-07 19:12:36,353 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 19:12:36,400 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 19:12:36,400 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 19:12:36,400 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 19:12:36,400 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 19:12:36,400 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 19:12:36,403 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 19:12:37,142 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1375436277_0001 running in uber mode : false
   [druid] 2018-12-07 19:12:37,144 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 19:12:42,248 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 19:12:43,147 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 50% reduce 0%
   [druid] 2018-12-07 19:12:44,789 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 19:12:44,791 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 19:12:44,791 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 19:12:44,791 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 362; bufvoid = 104857600
   [druid] 2018-12-07 19:12:44,791 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2018-12-07 19:12:44,901 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 19:12:44,907 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1375436277_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 19:12:44,908 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 19:12:44,908 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1375436277_0001_m_000000_0' done.
   [druid] 2018-12-07 19:12:44,909 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1375436277_0001_m_000000_0
   [druid] 2018-12-07 19:12:44,909 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 19:12:44,911 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 19:12:44,911 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1375436277_0001_r_000000_0
   [druid] 2018-12-07 19:12:44,917 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 19:12:44,917 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 19:12:45,002 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4bd80128
   [druid] 2018-12-07 19:12:45,005 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7a4b7b08
   [druid] 2018-12-07 19:12:45,017 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 19:12:45,019 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1375436277_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 19:12:45,045 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1375436277_0001_m_000000_0 decomp: 368 len: 372 to MEMORY
   [druid] 2018-12-07 19:12:45,050 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 368 bytes from map-output for attempt_local1375436277_0001_m_000000_0
   [druid] 2018-12-07 19:12:45,051 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 368, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->368
   [druid] 2018-12-07 19:12:45,053 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 19:12:45,053 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 19:12:45,053 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 19:12:45,129 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 19:12:45,129 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 19:12:45,131 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 368 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 19:12:45,132 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 372 bytes from disk
   [druid] 2018-12-07 19:12:45,132 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 19:12:45,132 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 19:12:45,133 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 19:12:45,133 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 19:12:45,142 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 19:12:45,148 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-12-07 19:12:45,179 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1375436277_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 19:12:45,180 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 19:12:45,180 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1375436277_0001_r_000000_0' done.
   [druid] 2018-12-07 19:12:45,180 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1375436277_0001_r_000000_0
   [druid] 2018-12-07 19:12:45,180 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 19:12:45,185 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 19:12:46,148 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 19:12:46,148 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1375436277_0001 completed successfully
   [druid] 2018-12-07 19:12:46,159 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1096
		FILE: Number of bytes written=611224
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=2
		Map output bytes=362
		Map output materialized bytes=372
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=372
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=52
		Total committed heap usage (bytes)=686817280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-07 19:14:21,602 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-07 19:14:21,604 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-07 19:14:22,328 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-07 19:14:22,400 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-07 19:14:22,426 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-07 19:14:22,487 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1751377887_0001
   [druid] 2018-12-07 19:14:22,602 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-07 19:14:22,603 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1751377887_0001
   [druid] 2018-12-07 19:14:22,604 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-07 19:14:22,609 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 19:14:22,609 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-07 19:14:22,615 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-07 19:14:22,647 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-07 19:14:22,649 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1751377887_0001_m_000000_0
   [druid] 2018-12-07 19:14:22,672 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 19:14:22,676 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 19:14:22,746 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@611c21b3
   [druid] 2018-12-07 19:14:22,754 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-07 19:14:22,797 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-07 19:14:22,797 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-07 19:14:22,798 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-07 19:14:22,798 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-07 19:14:22,798 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-07 19:14:22,800 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-07 19:14:23,605 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1751377887_0001 running in uber mode : false
   [druid] 2018-12-07 19:14:23,606 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-07 19:14:28,681 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 19:14:29,609 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 47% reduce 0%
   [druid] 2018-12-07 19:14:31,682 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 19:14:31,932 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-07 19:14:31,933 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-07 19:14:31,933 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-07 19:14:31,934 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 362; bufvoid = 104857600
   [druid] 2018-12-07 19:14:31,934 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
   [druid] 2018-12-07 19:14:32,042 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-07 19:14:32,050 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1751377887_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 19:14:32,051 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-07 19:14:32,051 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1751377887_0001_m_000000_0' done.
   [druid] 2018-12-07 19:14:32,051 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1751377887_0001_m_000000_0
   [druid] 2018-12-07 19:14:32,052 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-07 19:14:32,054 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-07 19:14:32,054 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1751377887_0001_r_000000_0
   [druid] 2018-12-07 19:14:32,064 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-07 19:14:32,064 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-07 19:14:32,150 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@57f5b74f
   [druid] 2018-12-07 19:14:32,152 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2324b3b1
   [druid] 2018-12-07 19:14:32,164 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-07 19:14:32,166 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1751377887_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-07 19:14:32,190 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1751377887_0001_m_000000_0 decomp: 368 len: 372 to MEMORY
   [druid] 2018-12-07 19:14:32,194 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 368 bytes from map-output for attempt_local1751377887_0001_m_000000_0
   [druid] 2018-12-07 19:14:32,195 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 368, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->368
   [druid] 2018-12-07 19:14:32,196 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-07 19:14:32,197 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 19:14:32,197 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-07 19:14:32,206 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 19:14:32,206 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 19:14:32,208 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 368 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-07 19:14:32,209 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 372 bytes from disk
   [druid] 2018-12-07 19:14:32,209 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-07 19:14:32,209 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-07 19:14:32,210 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 259 bytes
   [druid] 2018-12-07 19:14:32,210 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-07 19:14:32,220 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-07 19:14:32,282 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1751377887_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-07 19:14:32,283 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-07 19:14:32,283 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1751377887_0001_r_000000_0' done.
   [druid] 2018-12-07 19:14:32,283 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1751377887_0001_r_000000_0
   [druid] 2018-12-07 19:14:32,284 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-07 19:14:32,288 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-07 19:14:32,610 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-07 19:14:32,610 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1751377887_0001 completed successfully
   [druid] 2018-12-07 19:14:32,621 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1096
		FILE: Number of bytes written=611224
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=2
		Map output bytes=362
		Map output materialized bytes=372
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=372
		Reduce input records=2
		Reduce output records=1
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=59
		Total committed heap usage (bytes)=686817280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   