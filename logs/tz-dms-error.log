2018-11-30 20:47:41,312 - [com.phone.etl.mapreduce.Etl2HdfsDriver.handleInputOutput(Etl2HdfsDriver.java:82)] ERROR [com.phone.etl.mapreduce.Etl2HdfsDriver] - 设置输入输出路径异常
java.lang.RuntimeException: 输入路径不存在/logs/11/29
	at com.phone.etl.mapreduce.Etl2HdfsDriver.handleInputOutput(Etl2HdfsDriver.java:75)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.run(Etl2HdfsDriver.java:55)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:31)
2018-11-30 20:47:41,400 - [com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:33)] ERROR [com.phone.etl.mapreduce.Etl2HdfsDriver] - 执行etl异常
org.apache.hadoop.mapred.InvalidJobConfException: Output directory not set.
	at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:138)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:266)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:139)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1290)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1287)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1308)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.run(Etl2HdfsDriver.java:56)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:31)
2018-11-30 20:48:55,131 - [com.phone.etl.mapreduce.Etl2HdfsDriver.handleInputOutput(Etl2HdfsDriver.java:82)] ERROR [com.phone.etl.mapreduce.Etl2HdfsDriver] - 设置输入输出路径异常
java.lang.RuntimeException: 输入路径不存在/logs/11/29
	at com.phone.etl.mapreduce.Etl2HdfsDriver.handleInputOutput(Etl2HdfsDriver.java:75)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.run(Etl2HdfsDriver.java:55)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:31)
2018-11-30 20:48:55,165 - [com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:33)] ERROR [com.phone.etl.mapreduce.Etl2HdfsDriver] - 执行etl异常
org.apache.hadoop.mapred.InvalidJobConfException: Output directory not set.
	at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:138)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:266)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:139)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1290)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1287)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1308)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.run(Etl2HdfsDriver.java:56)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:31)
2018-11-30 20:52:42,285 - [com.phone.etl.mapreduce.Etl2HdfsDriver.handleInputOutput(Etl2HdfsDriver.java:84)] ERROR [com.phone.etl.mapreduce.Etl2HdfsDriver] - 设置输入输出路径异常
java.lang.IllegalArgumentException: Pathname /e:/test/log/input from e:/test/log/input is not a valid DFS filename.
	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:197)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:106)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1305)
	at org.apache.hadoop.hdfs.DistributedFileSystem$22.doCall(DistributedFileSystem.java:1301)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1317)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1424)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.handleInputOutput(Etl2HdfsDriver.java:74)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.run(Etl2HdfsDriver.java:55)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:31)
2018-11-30 20:52:42,318 - [com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:33)] ERROR [com.phone.etl.mapreduce.Etl2HdfsDriver] - 执行etl异常
org.apache.hadoop.mapred.InvalidJobConfException: Output directory not set.
	at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:138)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:266)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:139)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1290)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1287)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1308)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.run(Etl2HdfsDriver.java:56)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:31)
2018-12-03 14:32:09,204 - [com.phone.etl.mapreduce.Etl2HdfsDriver.handleInputOutput(Etl2HdfsDriver.java:82)] ERROR [com.phone.etl.mapreduce.Etl2HdfsDriver] - 设置输入输出路径异常
java.lang.RuntimeException: 输入路径不存在/logs/11/11
	at com.phone.etl.mapreduce.Etl2HdfsDriver.handleInputOutput(Etl2HdfsDriver.java:75)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.run(Etl2HdfsDriver.java:55)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:31)
2018-12-03 14:32:09,286 - [com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:33)] ERROR [com.phone.etl.mapreduce.Etl2HdfsDriver] - 执行etl异常
org.apache.hadoop.mapred.InvalidJobConfException: Output directory not set.
	at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:138)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:266)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:139)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1290)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1287)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1308)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.run(Etl2HdfsDriver.java:56)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:31)
2018-12-04 20:47:28,204 - [com.phone.etl.mapreduce.Etl2HdfsDriver.handleInputOutput(Etl2HdfsDriver.java:84)] ERROR [com.phone.etl.mapreduce.Etl2HdfsDriver] - 设置输入输出路径异常
java.lang.RuntimeException: 输入路径不存在/logs/2018-05-28
	at com.phone.etl.mapreduce.Etl2HdfsDriver.handleInputOutput(Etl2HdfsDriver.java:77)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.run(Etl2HdfsDriver.java:55)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:31)
2018-12-04 20:47:28,256 - [com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:33)] ERROR [com.phone.etl.mapreduce.Etl2HdfsDriver] - 执行etl异常
org.apache.hadoop.mapred.InvalidJobConfException: Output directory not set.
	at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:138)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:266)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:139)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1290)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1287)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1287)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1308)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.run(Etl2HdfsDriver.java:56)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at com.phone.etl.mapreduce.Etl2HdfsDriver.main(Etl2HdfsDriver.java:31)
2018-12-06 15:59:41,072 - [org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2644)] FATAL [org.apache.hadoop.conf.Configuration] - error parsing conf 
org.xml.sax.SAXParseException; systemId: file:/E:/JavaProjects/GP1815_LogAnalysis/target/classes/; lineNumber: 1; columnNumber: 1; Content is not allowed in prolog.
	at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)
	at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:150)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2480)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2468)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2539)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2502)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2405)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:981)
	at com.phone.analysis.OutputToMysqlFormat$OutputToMysqlRecordWriter.write(OutputToMysqlFormat.java:88)
	at com.phone.analysis.OutputToMysqlFormat$OutputToMysqlRecordWriter.write(OutputToMysqlFormat.java:47)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:558)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at com.phone.analysis.mapreduce.NewTotalUser.NewTotalUserReducer.reduce(NewTotalUserReducer.java:40)
	at com.phone.analysis.mapreduce.NewTotalUser.NewTotalUserReducer.reduce(NewTotalUserReducer.java:21)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-12-06 16:00:34,174 - [org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2644)] FATAL [org.apache.hadoop.conf.Configuration] - error parsing conf 
org.xml.sax.SAXParseException; systemId: file:/E:/JavaProjects/GP1815_LogAnalysis/target/classes/; lineNumber: 1; columnNumber: 1; Content is not allowed in prolog.
	at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)
	at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:150)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2480)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2468)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2539)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2502)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2405)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:981)
	at com.phone.analysis.OutputToMysqlFormat$OutputToMysqlRecordWriter.write(OutputToMysqlFormat.java:88)
	at com.phone.analysis.OutputToMysqlFormat$OutputToMysqlRecordWriter.write(OutputToMysqlFormat.java:47)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:558)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at com.phone.analysis.mapreduce.NewTotalUser.NewTotalUserReducer.reduce(NewTotalUserReducer.java:40)
	at com.phone.analysis.mapreduce.NewTotalUser.NewTotalUserReducer.reduce(NewTotalUserReducer.java:21)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-12-06 16:01:14,529 - [org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2644)] FATAL [org.apache.hadoop.conf.Configuration] - error parsing conf 
org.xml.sax.SAXParseException; systemId: file:/E:/JavaProjects/GP1815_LogAnalysis/target/classes/; lineNumber: 1; columnNumber: 1; Content is not allowed in prolog.
	at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)
	at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:150)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2480)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2468)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2539)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2502)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2405)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:981)
	at com.phone.analysis.OutputToMysqlFormat$OutputToMysqlRecordWriter.write(OutputToMysqlFormat.java:88)
	at com.phone.analysis.OutputToMysqlFormat$OutputToMysqlRecordWriter.write(OutputToMysqlFormat.java:47)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:558)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at com.phone.analysis.mapreduce.NewTotalUser.NewTotalUserReducer.reduce(NewTotalUserReducer.java:40)
	at com.phone.analysis.mapreduce.NewTotalUser.NewTotalUserReducer.reduce(NewTotalUserReducer.java:21)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-12-06 16:02:35,316 - [org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2644)] FATAL [org.apache.hadoop.conf.Configuration] - error parsing conf 
org.xml.sax.SAXParseException; systemId: file:/E:/JavaProjects/GP1815_LogAnalysis/target/classes/; lineNumber: 1; columnNumber: 1; Content is not allowed in prolog.
	at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)
	at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:150)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2480)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2468)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2539)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2502)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2405)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:981)
	at com.phone.analysis.OutputToMysqlFormat$OutputToMysqlRecordWriter.write(OutputToMysqlFormat.java:88)
	at com.phone.analysis.OutputToMysqlFormat$OutputToMysqlRecordWriter.write(OutputToMysqlFormat.java:47)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:558)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at com.phone.analysis.mapreduce.NewTotalUser.NewTotalUserReducer.reduce(NewTotalUserReducer.java:40)
	at com.phone.analysis.mapreduce.NewTotalUser.NewTotalUserReducer.reduce(NewTotalUserReducer.java:21)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-12-06 16:05:38,063 - [org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2644)] FATAL [org.apache.hadoop.conf.Configuration] - error parsing conf 
org.xml.sax.SAXParseException; systemId: file:/E:/JavaProjects/GP1815_LogAnalysis/target/classes/; lineNumber: 1; columnNumber: 1; Content is not allowed in prolog.
	at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)
	at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:150)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2480)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2468)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2539)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2502)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2405)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:981)
	at com.phone.analysis.OutputToMysqlFormat$OutputToMysqlRecordWriter.write(OutputToMysqlFormat.java:88)
	at com.phone.analysis.OutputToMysqlFormat$OutputToMysqlRecordWriter.write(OutputToMysqlFormat.java:47)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:558)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at com.phone.analysis.mapreduce.NewTotalUser.NewTotalUserReducer.reduce(NewTotalUserReducer.java:40)
	at com.phone.analysis.mapreduce.NewTotalUser.NewTotalUserReducer.reduce(NewTotalUserReducer.java:21)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
