[druid] 2018-12-05 01:27:11,988 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 01:27:12,009 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 01:27:13,196 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 01:27:13,361 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 01:27:13,425 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 01:27:13,589 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local408186951_0001
   [druid] 2018-12-05 01:27:13,856 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 01:27:13,859 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local408186951_0001
   [druid] 2018-12-05 01:27:13,862 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 01:27:13,871 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 01:27:13,872 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 01:27:13,885 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 01:27:13,950 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 01:27:13,952 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local408186951_0001_m_000000_0
   [druid] 2018-12-05 01:27:13,995 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 01:27:14,003 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 01:27:14,867 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local408186951_0001 running in uber mode : false
   [druid] 2018-12-05 01:27:14,873 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 01:27:17,285 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@282d37b6
   [druid] 2018-12-05 01:27:17,297 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 01:27:17,389 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 01:27:17,393 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 01:27:17,393 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 01:27:17,393 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 01:27:17,393 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 01:27:17,399 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 01:27:18,205 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 01:27:18,206 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 01:27:18,207 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 01:27:18,207 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 01:27:18,207 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 01:27:18,208 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 01:27:18,208 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 01:27:18,209 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 01:27:18,209 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 01:27:23,031 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 01:27:23,894 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 4% reduce 0%
   [druid] 2018-12-05 01:27:24,781 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 01:27:24,781 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 01:27:24,781 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 40020; bufvoid = 104857600
   [druid] 2018-12-05 01:27:24,781 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26213192(104852768); length = 1205/6553600
   [druid] 2018-12-05 01:27:24,938 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 01:27:24,953 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 01:27:24,953 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in cleanupJob()
   [druid] 2018-12-05 01:27:24,954 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local408186951_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at com.phone.analysis.mapreduce.NewMember.findMember.insertMember(findMember.java:63)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:74)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:28)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-05 01:27:25,898 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local408186951_0001 failed with state FAILED due to: NA
   [druid] 2018-12-05 01:27:25,923 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 22
	File System Counters
		FILE: Number of bytes read=160
		FILE: Number of bytes written=300054
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=45056
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=115
		Map output records=210
		Map output bytes=27794
		Map output materialized bytes=0
		Input split bytes=106
		Combine input records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=316145664
	File Input Format Counters 
		Bytes Read=45056
   [druid] 2018-12-05 11:04:08,370 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 11:04:08,400 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 11:04:09,153 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 11:04:09,253 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 11:04:09,320 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 11:04:09,425 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1838523596_0001
   [druid] 2018-12-05 11:04:09,667 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 11:04:09,668 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1838523596_0001
   [druid] 2018-12-05 11:04:09,670 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 11:04:09,676 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 11:04:09,676 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 11:04:09,687 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 11:04:09,738 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 11:04:09,739 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1838523596_0001_m_000000_0
   [druid] 2018-12-05 11:04:09,763 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 11:04:09,767 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 11:04:10,195 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3c6b45a2
   [druid] 2018-12-05 11:04:10,202 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 11:04:10,362 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 11:04:10,362 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 11:04:10,362 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 11:04:10,362 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 11:04:10,362 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 11:04:10,449 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 11:04:10,670 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1838523596_0001 running in uber mode : false
   [druid] 2018-12-05 11:04:10,671 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 11:04:10,911 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:04:10,911 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:04:10,912 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:04:10,912 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:04:10,912 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:04:10,912 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:04:10,912 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:04:10,912 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:04:10,912 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:04:14,259 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 11:04:14,259 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 11:04:14,259 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 40020; bufvoid = 104857600
   [druid] 2018-12-05 11:04:14,259 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26213192(104852768); length = 1205/6553600
   [druid] 2018-12-05 11:04:14,437 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 11:04:14,444 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 11:04:14,444 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in cleanupJob()
   [druid] 2018-12-05 11:04:14,444 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1838523596_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at com.phone.analysis.mapreduce.NewMember.findMember.insertMember(findMember.java:63)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:74)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:28)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-05 11:04:14,676 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1838523596_0001 failed with state FAILED due to: NA
   [druid] 2018-12-05 11:04:14,686 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2018-12-05 11:35:05,415 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 11:35:05,416 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 11:35:06,072 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 11:35:06,124 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 11:35:06,155 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 11:35:06,226 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local71303722_0001
   [druid] 2018-12-05 11:35:06,388 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 11:35:06,389 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local71303722_0001
   [druid] 2018-12-05 11:35:06,391 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 11:35:06,398 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 11:35:06,398 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 11:35:06,405 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 11:35:06,443 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 11:35:06,445 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local71303722_0001_m_000000_0
   [druid] 2018-12-05 11:35:06,477 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 11:35:06,482 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 11:35:06,664 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4bd15d76
   [druid] 2018-12-05 11:35:06,676 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 11:35:06,734 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 11:35:06,734 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 11:35:06,734 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 11:35:06,734 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 11:35:06,734 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 11:35:06,739 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 11:35:07,173 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:35:07,174 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:35:07,174 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:35:07,174 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:35:07,174 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:35:07,174 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:35:07,175 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:35:07,175 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:35:07,175 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 11:35:07,392 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local71303722_0001 running in uber mode : false
   [druid] 2018-12-05 11:35:07,394 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 11:35:39,381 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 11:36:02,545 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 11:36:06,353 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 11:36:09,795 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 11:36:13,939 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 11:36:17,620 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 11:36:22,357 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 11:44:14,182 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 11:46:41,251 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:02:26,185 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:02:26,186 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:02:26,790 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 12:02:26,869 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:02:26,907 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 12:02:26,963 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1118352730_0001
   [druid] 2018-12-05 12:02:27,088 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 12:02:27,089 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1118352730_0001
   [druid] 2018-12-05 12:02:27,090 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:02:27,094 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:02:27,094 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:02:27,099 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 12:02:27,128 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:02:27,129 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1118352730_0001_m_000000_0
   [druid] 2018-12-05 12:02:27,149 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:02:27,152 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:02:27,219 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5f2d6f66
   [druid] 2018-12-05 12:02:27,224 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 12:02:27,268 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 12:02:27,268 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 12:02:27,268 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 12:02:27,268 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 12:02:27,268 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 12:02:27,271 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 12:02:27,699 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:02:27,699 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:02:27,699 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:02:27,699 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:02:27,699 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:02:27,699 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:02:27,700 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:02:27,700 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:02:27,700 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:02:28,091 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1118352730_0001 running in uber mode : false
   [druid] 2018-12-05 12:02:28,093 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 12:02:30,745 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:02:30,745 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 12:02:30,745 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 37370; bufvoid = 104857600
   [druid] 2018-12-05 12:02:30,745 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26213272(104853088); length = 1125/6553600
   [druid] 2018-12-05 12:02:30,767 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 12:02:30,775 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 12:02:30,775 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in cleanupJob()
   [druid] 2018-12-05 12:02:30,776 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1118352730_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at com.phone.analysis.mapreduce.NewMember.findMember.insertMember(findMember.java:63)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:74)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:28)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-05 12:02:31,096 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1118352730_0001 failed with state FAILED due to: NA
   [druid] 2018-12-05 12:02:31,100 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2018-12-05 12:04:01,551 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:04:01,552 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:04:02,109 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 12:04:02,173 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:04:02,209 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 12:04:02,294 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1263474705_0001
   [druid] 2018-12-05 12:04:02,459 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 12:04:02,460 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1263474705_0001
   [druid] 2018-12-05 12:04:02,461 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:04:02,467 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:04:02,467 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:04:02,475 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 12:04:02,521 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:04:02,523 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1263474705_0001_m_000000_0
   [druid] 2018-12-05 12:04:02,549 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:04:02,553 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:04:02,618 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@513ac1d3
   [druid] 2018-12-05 12:04:02,624 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 12:04:02,671 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 12:04:02,671 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 12:04:02,671 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 12:04:02,671 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 12:04:02,671 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 12:04:02,674 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 12:04:03,087 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:04:03,087 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:04:03,087 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:04:03,088 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:04:03,088 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:04:03,088 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:04:03,088 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:04:03,088 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:04:03,088 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:04:03,463 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1263474705_0001 running in uber mode : false
   [druid] 2018-12-05 12:04:03,464 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 12:04:06,099 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:04:06,099 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 12:04:06,099 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 37370; bufvoid = 104857600
   [druid] 2018-12-05 12:04:06,099 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26213272(104853088); length = 1125/6553600
   [druid] 2018-12-05 12:04:06,211 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 12:04:06,218 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 12:04:06,218 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in cleanupJob()
   [druid] 2018-12-05 12:04:06,219 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1263474705_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at com.phone.analysis.mapreduce.NewMember.findMember.insertMember(findMember.java:63)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:74)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:28)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-05 12:04:06,466 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1263474705_0001 failed with state FAILED due to: NA
   [druid] 2018-12-05 12:04:06,472 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2018-12-05 12:05:04,413 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:05:04,414 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:05:04,920 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 12:05:04,982 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:05:05,008 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 12:05:05,064 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1911318562_0001
   [druid] 2018-12-05 12:05:05,180 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 12:05:05,181 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1911318562_0001
   [druid] 2018-12-05 12:05:05,182 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:05:05,187 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:05:05,187 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:05:05,192 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 12:05:05,218 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:05:05,220 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1911318562_0001_m_000000_0
   [druid] 2018-12-05 12:05:05,240 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:05:05,243 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:05:05,307 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@159ccee1
   [druid] 2018-12-05 12:05:05,313 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 12:05:05,357 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 12:05:05,357 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 12:05:05,357 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 12:05:05,357 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 12:05:05,357 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 12:05:05,360 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 12:05:05,782 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:05:05,782 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:05:05,783 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:05:05,783 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:05:05,783 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:05:05,783 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:05:05,784 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:05:05,784 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:05:05,784 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:05:06,182 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1911318562_0001 running in uber mode : false
   [druid] 2018-12-05 12:05:06,185 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 12:05:08,670 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:05:08,670 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 12:05:08,670 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 37370; bufvoid = 104857600
   [druid] 2018-12-05 12:05:08,670 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26213272(104853088); length = 1125/6553600
   [druid] 2018-12-05 12:05:08,819 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 12:05:08,825 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 12:05:08,825 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in cleanupJob()
   [druid] 2018-12-05 12:05:08,826 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1911318562_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at com.phone.analysis.mapreduce.NewMember.findMember.insertMember(findMember.java:63)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:74)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:28)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-05 12:05:09,188 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1911318562_0001 failed with state FAILED due to: NA
   [druid] 2018-12-05 12:05:09,193 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2018-12-05 12:08:58,464 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:08:58,465 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:08:59,023 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 12:08:59,097 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:08:59,126 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 12:08:59,187 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1877786084_0001
   [druid] 2018-12-05 12:08:59,315 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 12:08:59,316 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1877786084_0001
   [druid] 2018-12-05 12:08:59,316 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:08:59,322 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:08:59,322 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:08:59,328 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 12:08:59,359 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:08:59,360 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1877786084_0001_m_000000_0
   [druid] 2018-12-05 12:08:59,379 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:08:59,383 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:08:59,566 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4bbfb976
   [druid] 2018-12-05 12:08:59,574 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 12:08:59,627 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 12:08:59,627 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 12:08:59,627 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 12:08:59,627 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 12:08:59,627 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 12:08:59,630 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 12:09:00,167 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:09:00,167 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:09:00,167 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:09:00,168 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:09:00,168 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:09:00,168 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:09:00,168 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:09:00,168 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:09:00,169 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:09:00,317 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1877786084_0001 running in uber mode : false
   [druid] 2018-12-05 12:09:00,318 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 12:09:01,602 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:09:01,602 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 12:09:01,602 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 514; bufvoid = 104857600
   [druid] 2018-12-05 12:09:01,602 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
   [druid] 2018-12-05 12:09:01,612 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 12:09:01,617 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 12:09:01,617 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in cleanupJob()
   [druid] 2018-12-05 12:09:01,619 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1877786084_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NullPointerException
	at com.phone.analysis.mapreduce.NewMember.findMember.find(findMember.java:29)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:70)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:28)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-05 12:09:02,321 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1877786084_0001 failed with state FAILED due to: NA
   [druid] 2018-12-05 12:09:02,326 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2018-12-05 12:12:06,977 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:12:06,979 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:12:07,552 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 12:12:07,622 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:12:07,650 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 12:12:07,712 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local4198738_0001
   [druid] 2018-12-05 12:12:07,841 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 12:12:07,842 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local4198738_0001
   [druid] 2018-12-05 12:12:07,843 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:12:07,848 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:12:07,848 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:12:07,853 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 12:12:07,883 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:12:07,885 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local4198738_0001_m_000000_0
   [druid] 2018-12-05 12:12:07,912 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:12:07,916 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:12:07,988 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@393038ee
   [druid] 2018-12-05 12:12:07,997 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 12:12:08,045 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 12:12:08,045 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 12:12:08,045 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 12:12:08,045 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 12:12:08,045 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 12:12:08,048 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 12:12:08,494 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:12:08,494 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:12:08,495 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:12:08,495 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:12:08,495 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:12:08,495 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:12:08,495 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:12:08,496 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:12:08,496 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:12:08,843 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local4198738_0001 running in uber mode : false
   [druid] 2018-12-05 12:12:08,844 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 12:12:13,924 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:12:14,849 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 27% reduce 0%
   [druid] 2018-12-05 12:12:16,925 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:12:17,850 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 44% reduce 0%
   [druid] 2018-12-05 12:12:19,926 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:12:20,851 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 61% reduce 0%
   [druid] 2018-12-05 12:12:21,343 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:12:21,375 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:12:21,375 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 12:12:21,375 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 492; bufvoid = 104857600
   [druid] 2018-12-05 12:12:21,375 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
   [druid] 2018-12-05 12:12:21,397 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 12:12:21,402 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local4198738_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:12:21,403 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 12:12:21,403 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local4198738_0001_m_000000_0' done.
   [druid] 2018-12-05 12:12:21,404 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local4198738_0001_m_000000_0
   [druid] 2018-12-05 12:12:21,404 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 12:12:21,413 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 12:12:21,414 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local4198738_0001_r_000000_0
   [druid] 2018-12-05 12:12:21,419 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:12:21,419 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:12:21,500 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@ffef5d9
   [druid] 2018-12-05 12:12:21,516 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1e426996
   [druid] 2018-12-05 12:12:21,548 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 12:12:21,548 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local4198738_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 12:12:21,577 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local4198738_0001_m_000000_0 decomp: 502 len: 506 to MEMORY
   [druid] 2018-12-05 12:12:21,581 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 502 bytes from map-output for attempt_local4198738_0001_m_000000_0
   [druid] 2018-12-05 12:12:21,583 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 502, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->502
   [druid] 2018-12-05 12:12:21,584 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 12:12:21,585 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:12:21,585 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 12:12:21,594 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:12:21,595 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 422 bytes
   [druid] 2018-12-05 12:12:21,597 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 502 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 12:12:21,598 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 506 bytes from disk
   [druid] 2018-12-05 12:12:21,599 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 12:12:21,599 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:12:21,599 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 422 bytes
   [druid] 2018-12-05 12:12:21,600 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:12:21,680 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 12:12:21,778 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local4198738_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:12:21,779 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 12:12:21,779 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local4198738_0001_r_000000_0' done.
   [druid] 2018-12-05 12:12:21,779 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local4198738_0001_r_000000_0
   [druid] 2018-12-05 12:12:21,779 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 12:12:21,783 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 12:12:21,852 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 12:12:21,852 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local4198738_0001 completed successfully
   [druid] 2018-12-05 12:12:21,864 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1364
		FILE: Number of bytes written=595530
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=4
		Map output bytes=492
		Map output materialized bytes=506
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=506
		Reduce input records=4
		Reduce output records=2
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=130
		Total committed heap usage (bytes)=791674880
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 12:15:03,846 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:15:03,847 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:15:04,426 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 12:15:04,495 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:15:04,522 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 12:15:04,583 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1164016984_0001
   [druid] 2018-12-05 12:15:04,699 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 12:15:04,700 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1164016984_0001
   [druid] 2018-12-05 12:15:04,701 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:15:04,706 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:15:04,706 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:15:04,711 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 12:15:04,753 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:15:04,755 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1164016984_0001_m_000000_0
   [druid] 2018-12-05 12:15:04,781 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:15:04,785 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:15:04,856 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5f2d6f66
   [druid] 2018-12-05 12:15:04,863 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 12:15:04,907 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 12:15:04,907 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 12:15:04,907 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 12:15:04,907 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 12:15:04,907 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 12:15:04,911 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 12:15:05,346 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:15:05,346 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:15:05,347 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:15:05,347 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:15:05,347 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:15:05,347 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:15:05,348 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:15:05,348 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:15:05,348 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:15:05,701 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1164016984_0001 running in uber mode : false
   [druid] 2018-12-05 12:15:05,702 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 12:15:10,855 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:15:11,706 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 28% reduce 0%
   [druid] 2018-12-05 12:15:13,857 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:15:14,707 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 45% reduce 0%
   [druid] 2018-12-05 12:15:16,857 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:15:17,708 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 62% reduce 0%
   [druid] 2018-12-05 12:15:17,749 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:15:17,750 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:15:17,856 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1164016984_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:15:17,857 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 12:15:17,857 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1164016984_0001_m_000000_0' done.
   [druid] 2018-12-05 12:15:17,857 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1164016984_0001_m_000000_0
   [druid] 2018-12-05 12:15:17,857 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 12:15:17,859 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 12:15:17,860 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1164016984_0001_r_000000_0
   [druid] 2018-12-05 12:15:17,865 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:15:17,865 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:15:17,937 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@536af140
   [druid] 2018-12-05 12:15:17,940 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6871ada5
   [druid] 2018-12-05 12:15:17,953 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 12:15:17,956 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1164016984_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 12:15:17,982 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1164016984_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-05 12:15:17,987 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1164016984_0001_m_000000_0
   [druid] 2018-12-05 12:15:17,988 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-05 12:15:17,989 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 12:15:17,990 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:15:17,990 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 12:15:18,001 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:15:18,001 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-05 12:15:18,003 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 12:15:18,004 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-05 12:15:18,004 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 12:15:18,004 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:15:18,006 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-05 12:15:18,007 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:15:18,022 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 12:15:18,025 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1164016984_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:15:18,026 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 12:15:18,026 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1164016984_0001_r_000000_0' done.
   [druid] 2018-12-05 12:15:18,026 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1164016984_0001_r_000000_0
   [druid] 2018-12-05 12:15:18,027 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 12:15:18,032 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 12:15:18,709 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 12:15:18,709 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1164016984_0001 completed successfully
   [druid] 2018-12-05 12:15:18,719 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=603270
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=122
		Total committed heap usage (bytes)=786432000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 12:17:54,934 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:17:54,935 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:17:55,500 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 12:17:55,563 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:17:55,588 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 12:17:55,648 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1645361302_0001
   [druid] 2018-12-05 12:17:55,753 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 12:17:55,754 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1645361302_0001
   [druid] 2018-12-05 12:17:55,755 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:17:55,758 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:17:55,758 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:17:55,762 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 12:17:55,789 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:17:55,791 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1645361302_0001_m_000000_0
   [druid] 2018-12-05 12:17:55,811 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:17:55,815 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:17:55,882 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@38522b56
   [druid] 2018-12-05 12:17:55,889 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 12:17:55,932 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 12:17:55,932 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 12:17:55,932 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 12:17:55,932 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 12:17:55,932 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 12:17:55,935 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 12:17:56,353 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:17:56,353 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:17:56,353 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:17:56,354 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:17:56,354 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:17:56,354 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:17:56,354 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:17:56,354 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:17:56,355 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:17:56,755 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1645361302_0001 running in uber mode : false
   [druid] 2018-12-05 12:17:56,756 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 12:18:01,880 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:18:02,760 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 29% reduce 0%
   [druid] 2018-12-05 12:18:04,880 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:18:05,761 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 47% reduce 0%
   [druid] 2018-12-05 12:18:08,052 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:18:08,393 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:18:08,395 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:18:08,426 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1645361302_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:18:08,428 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 12:18:08,428 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1645361302_0001_m_000000_0' done.
   [druid] 2018-12-05 12:18:08,428 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1645361302_0001_m_000000_0
   [druid] 2018-12-05 12:18:08,428 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 12:18:08,430 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 12:18:08,430 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1645361302_0001_r_000000_0
   [druid] 2018-12-05 12:18:08,437 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:18:08,437 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:18:08,526 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6e08b0dd
   [druid] 2018-12-05 12:18:08,528 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6a3d1c86
   [druid] 2018-12-05 12:18:08,539 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 12:18:08,541 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1645361302_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 12:18:08,565 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1645361302_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-05 12:18:08,569 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1645361302_0001_m_000000_0
   [druid] 2018-12-05 12:18:08,570 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-05 12:18:08,571 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 12:18:08,572 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:18:08,572 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 12:18:08,582 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:18:08,583 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-05 12:18:08,585 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 12:18:08,586 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-05 12:18:08,586 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 12:18:08,586 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:18:08,588 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-05 12:18:08,588 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:18:08,607 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 12:18:08,612 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1645361302_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:18:08,613 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 12:18:08,613 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1645361302_0001_r_000000_0' done.
   [druid] 2018-12-05 12:18:08,613 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1645361302_0001_r_000000_0
   [druid] 2018-12-05 12:18:08,613 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 12:18:08,618 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 12:18:08,763 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 12:18:08,763 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1645361302_0001 completed successfully
   [druid] 2018-12-05 12:18:08,775 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=364
		FILE: Number of bytes written=603270
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=233
		Total committed heap usage (bytes)=1066401792
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 12:19:40,682 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:19:40,683 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:19:41,199 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 12:19:41,366 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:19:41,392 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 12:19:41,453 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local2133715825_0001
   [druid] 2018-12-05 12:19:41,567 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 12:19:41,568 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local2133715825_0001
   [druid] 2018-12-05 12:19:41,569 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:19:41,572 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:19:41,572 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:19:41,577 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 12:19:41,603 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:19:41,605 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2133715825_0001_m_000000_0
   [druid] 2018-12-05 12:19:41,623 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:19:41,627 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:19:41,696 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@159ccee1
   [druid] 2018-12-05 12:19:41,703 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 12:19:41,750 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 12:19:41,750 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 12:19:41,750 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 12:19:41,750 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 12:19:41,751 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 12:19:41,754 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 12:19:42,133 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:19:42,133 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:19:42,134 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:19:42,134 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:19:42,134 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:19:42,134 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:19:42,135 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:19:42,135 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:19:42,135 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:19:42,570 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local2133715825_0001 running in uber mode : false
   [druid] 2018-12-05 12:19:42,571 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 12:19:47,634 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:19:48,592 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 13% reduce 0%
   [druid] 2018-12-05 12:19:50,635 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:19:51,593 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 22% reduce 0%
   [druid] 2018-12-05 12:19:53,636 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:19:54,594 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 30% reduce 0%
   [druid] 2018-12-05 12:19:56,637 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:19:57,595 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 37% reduce 0%
   [druid] 2018-12-05 12:19:59,638 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:20:00,596 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 45% reduce 0%
   [druid] 2018-12-05 12:20:02,639 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:20:03,597 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 53% reduce 0%
   [druid] 2018-12-05 12:20:05,640 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:20:06,598 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 61% reduce 0%
   [druid] 2018-12-05 12:20:07,941 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:20:07,942 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:20:07,942 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 12:20:07,942 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 369512; bufvoid = 104857600
   [druid] 2018-12-05 12:20:07,943 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26201752(104807008); length = 12645/6553600
   [druid] 2018-12-05 12:20:08,008 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 12:20:08,016 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2133715825_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:20:08,017 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 12:20:08,018 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2133715825_0001_m_000000_0' done.
   [druid] 2018-12-05 12:20:08,018 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2133715825_0001_m_000000_0
   [druid] 2018-12-05 12:20:08,018 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 12:20:08,020 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 12:20:08,020 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local2133715825_0001_r_000000_0
   [druid] 2018-12-05 12:20:08,032 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:20:08,032 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:20:08,122 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6c3f3ffd
   [druid] 2018-12-05 12:20:08,126 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@64fc74ff
   [druid] 2018-12-05 12:20:08,136 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 12:20:08,138 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local2133715825_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 12:20:08,168 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local2133715825_0001_m_000000_0 decomp: 375838 len: 375842 to MEMORY
   [druid] 2018-12-05 12:20:08,172 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 375838 bytes from map-output for attempt_local2133715825_0001_m_000000_0
   [druid] 2018-12-05 12:20:08,173 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 375838, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->375838
   [druid] 2018-12-05 12:20:08,174 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 12:20:08,175 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:20:08,175 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 12:20:08,186 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:20:08,186 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 375765 bytes
   [druid] 2018-12-05 12:20:08,195 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 375838 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 12:20:08,196 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 375842 bytes from disk
   [druid] 2018-12-05 12:20:08,197 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 12:20:08,197 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:20:08,198 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 375765 bytes
   [druid] 2018-12-05 12:20:08,198 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:20:08,598 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-12-05 12:20:08,748 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 12:20:09,031 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local2133715825_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:20:09,032 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 12:20:09,032 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local2133715825_0001_r_000000_0' done.
   [druid] 2018-12-05 12:20:09,032 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local2133715825_0001_r_000000_0
   [druid] 2018-12-05 12:20:09,032 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 12:20:09,036 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 12:20:09,599 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 12:20:09,599 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local2133715825_0001 completed successfully
   [druid] 2018-12-05 12:20:09,611 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=752036
		FILE: Number of bytes written=1730778
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=3162
		Map output bytes=369512
		Map output materialized bytes=375842
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=375842
		Reduce input records=3162
		Reduce output records=14
		Spilled Records=6324
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=242
		Total committed heap usage (bytes)=796917760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 12:20:31,360 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:20:34,361 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:20:35,361 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 15% reduce 0%
   [druid] 2018-12-05 12:20:37,362 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:20:38,362 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 32% reduce 0%
   [druid] 2018-12-05 12:20:40,363 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:20:41,363 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 48% reduce 0%
   [druid] 2018-12-05 12:20:43,364 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:20:43,970 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 12:20:43,975 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:20:43,975 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 12:20:43,975 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 2840; bufvoid = 104857600
   [druid] 2018-12-05 12:20:43,975 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214312(104857248); length = 85/6553600
   [druid] 2018-12-05 12:20:43,990 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 12:20:43,998 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local71303722_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:20:44,000 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 12:20:44,000 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local71303722_0001_m_000000_0' done.
   [druid] 2018-12-05 12:20:44,000 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local71303722_0001_m_000000_0
   [druid] 2018-12-05 12:20:44,000 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 12:20:44,003 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 12:20:44,003 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local71303722_0001_r_000000_0
   [druid] 2018-12-05 12:20:44,012 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:20:44,012 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:20:44,083 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@64447884
   [druid] 2018-12-05 12:20:44,086 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e5bb03a
   [druid] 2018-12-05 12:20:44,098 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 12:20:44,101 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local71303722_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 12:20:44,130 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local71303722_0001_m_000000_0 decomp: 2886 len: 2890 to MEMORY
   [druid] 2018-12-05 12:20:44,135 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2886 bytes from map-output for attempt_local71303722_0001_m_000000_0
   [druid] 2018-12-05 12:20:44,137 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2886, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2886
   [druid] 2018-12-05 12:20:44,138 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 12:20:44,139 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:20:44,140 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 12:20:44,150 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:20:44,150 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 2813 bytes
   [druid] 2018-12-05 12:20:44,152 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2886 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 12:20:44,153 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 2890 bytes from disk
   [druid] 2018-12-05 12:20:44,153 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 12:20:44,153 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:20:44,154 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 2813 bytes
   [druid] 2018-12-05 12:20:44,154 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:20:44,170 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 12:20:44,245 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local71303722_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:20:44,246 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 12:20:44,246 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local71303722_0001_r_000000_0' done.
   [druid] 2018-12-05 12:20:44,246 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local71303722_0001_r_000000_0
   [druid] 2018-12-05 12:20:44,246 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 12:20:44,250 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 12:20:44,364 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 12:20:44,364 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local71303722_0001 completed successfully
   [druid] 2018-12-05 12:20:44,374 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=6132
		FILE: Number of bytes written=605762
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=22
		Map output bytes=2840
		Map output materialized bytes=2890
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=2890
		Reduce input records=22
		Reduce output records=3
		Spilled Records=44
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=225
		Total committed heap usage (bytes)=1047527424
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 12:24:33,632 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:24:33,633 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:24:34,208 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 12:24:34,217 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:24:34,295 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 12:24:34,355 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1568601757_0001
   [druid] 2018-12-05 12:24:34,478 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 12:24:34,479 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1568601757_0001
   [druid] 2018-12-05 12:24:34,480 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:24:34,485 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:24:34,487 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:24:34,535 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:24:34,535 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1568601757_0001_m_000000_0
   [druid] 2018-12-05 12:24:34,553 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:24:34,558 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:24:34,631 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5f1eed7
   [druid] 2018-12-05 12:24:34,635 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/logs/2017-05-30:0+1567
   [druid] 2018-12-05 12:24:35,480 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1568601757_0001 running in uber mode : false
   [druid] 2018-12-05 12:24:35,481 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 12:24:35,517 [ask Executor #0] INFO  e.etl.mapreduce.Etl2HdfsMapper {1} - 输入：3过滤：0输出：65
   [druid] 2018-12-05 12:24:35,520 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 12:24:35,844 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1568601757_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:24:35,850 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 12:24:35,850 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1568601757_0001_m_000000_0 is allowed to commit now
   [druid] 2018-12-05 12:24:35,859 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1568601757_0001_m_000000_0' to hdfs://Murphy:8020/ods/05/30/_temporary/0/task_local1568601757_0001_m_000000
   [druid] 2018-12-05 12:24:35,859 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 12:24:35,860 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1568601757_0001_m_000000_0' done.
   [druid] 2018-12-05 12:24:35,860 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1568601757_0001_m_000000_0
   [druid] 2018-12-05 12:24:35,860 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 12:24:36,483 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-12-05 12:24:36,483 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1568601757_0001 completed successfully
   [druid] 2018-12-05 12:24:36,492 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 20
	File System Counters
		FILE: Number of bytes read=152
		FILE: Number of bytes written=278450
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1567
		HDFS: Number of bytes written=27156
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Map input records=3
		Map output records=65
		Input split bytes=99
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=212336640
	File Input Format Counters 
		Bytes Read=1567
	File Output Format Counters 
		Bytes Written=27156
   [druid] 2018-12-05 12:25:39,447 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:25:39,448 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:25:40,011 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 12:25:40,080 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:25:40,107 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 12:25:40,166 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1370609204_0001
   [druid] 2018-12-05 12:25:40,285 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 12:25:40,286 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1370609204_0001
   [druid] 2018-12-05 12:25:40,287 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:25:40,291 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:25:40,291 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:25:40,295 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 12:25:40,326 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:25:40,327 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1370609204_0001_m_000000_0
   [druid] 2018-12-05 12:25:40,345 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:25:40,349 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:25:40,416 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1d319783
   [druid] 2018-12-05 12:25:40,423 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-05 12:25:40,468 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 12:25:40,468 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 12:25:40,468 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 12:25:40,468 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 12:25:40,468 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 12:25:40,471 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 12:25:40,884 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:40,884 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:40,884 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:40,885 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:40,885 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:40,885 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:40,885 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:40,885 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:40,885 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:40,885 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:40,886 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:40,886 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:40,886 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:40,886 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:25:41,287 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1370609204_0001 running in uber mode : false
   [druid] 2018-12-05 12:25:41,288 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 12:25:42,314 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 12:25:42,316 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:25:42,317 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 12:25:42,317 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 10738; bufvoid = 104857600
   [druid] 2018-12-05 12:25:42,317 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26213992(104855968); length = 405/6553600
   [druid] 2018-12-05 12:25:42,330 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 12:25:42,338 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1370609204_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:25:42,348 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 12:25:42,348 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1370609204_0001_m_000000_0' done.
   [druid] 2018-12-05 12:25:42,348 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1370609204_0001_m_000000_0
   [druid] 2018-12-05 12:25:42,348 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 12:25:42,351 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 12:25:42,352 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1370609204_0001_r_000000_0
   [druid] 2018-12-05 12:25:42,359 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:25:42,359 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:25:42,438 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@421cd0e9
   [druid] 2018-12-05 12:25:42,441 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4b432a8e
   [druid] 2018-12-05 12:25:42,455 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 12:25:42,456 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1370609204_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 12:25:42,487 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1370609204_0001_m_000000_0 decomp: 10944 len: 10948 to MEMORY
   [druid] 2018-12-05 12:25:42,491 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 10944 bytes from map-output for attempt_local1370609204_0001_m_000000_0
   [druid] 2018-12-05 12:25:42,493 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 10944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->10944
   [druid] 2018-12-05 12:25:42,494 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 12:25:42,495 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:25:42,495 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 12:25:42,597 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:25:42,597 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 10871 bytes
   [druid] 2018-12-05 12:25:42,601 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 10944 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 12:25:42,601 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 10948 bytes from disk
   [druid] 2018-12-05 12:25:42,602 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 12:25:42,602 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:25:42,603 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 10871 bytes
   [druid] 2018-12-05 12:25:42,603 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:25:42,619 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 12:25:42,769 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1370609204_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:25:42,769 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 12:25:42,769 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1370609204_0001_r_000000_0' done.
   [druid] 2018-12-05 12:25:42,769 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1370609204_0001_r_000000_0
   [druid] 2018-12-05 12:25:42,769 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 12:25:42,774 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 12:25:43,295 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 12:25:43,295 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1370609204_0001 completed successfully
   [druid] 2018-12-05 12:25:43,307 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=22246
		FILE: Number of bytes written=636094
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=65
		Map output records=102
		Map output bytes=10738
		Map output materialized bytes=10948
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=10948
		Reduce input records=102
		Reduce output records=6
		Spilled Records=204
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=634388480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27156
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 12:35:31,484 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:35:31,485 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:35:32,091 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 12:35:32,157 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:35:32,182 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 12:35:32,242 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1738036286_0001
   [druid] 2018-12-05 12:35:32,363 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 12:35:32,363 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1738036286_0001
   [druid] 2018-12-05 12:35:32,365 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:35:32,369 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:35:32,369 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:35:32,375 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 12:35:32,407 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:35:32,409 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1738036286_0001_m_000000_0
   [druid] 2018-12-05 12:35:32,430 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:35:32,435 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:35:32,515 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@109a569c
   [druid] 2018-12-05 12:35:32,521 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-05 12:35:32,568 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 12:35:32,568 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 12:35:32,569 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 12:35:32,569 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 12:35:32,569 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 12:35:32,572 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 12:35:33,010 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:35:33,039 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 12:35:33,040 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in cleanupJob()
   [druid] 2018-12-05 12:35:33,040 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1738036286_0001
   java.lang.Exception: java.lang.NumberFormatException: For input string: "null"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NumberFormatException: For input string: "null"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:589)
	at java.lang.Long.parseLong(Long.java:631)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:64)
	at com.phone.analysis.mapreduce.NewMember.NewMemberMapper.map(NewMemberMapper.java:29)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2018-12-05 12:35:33,365 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1738036286_0001 running in uber mode : false
   [druid] 2018-12-05 12:35:33,366 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 12:35:33,368 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1738036286_0001 failed with state FAILED due to: NA
   [druid] 2018-12-05 12:35:33,371 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2018-12-05 12:37:01,116 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 12:37:01,117 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 12:37:01,656 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 12:37:01,723 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 12:37:01,750 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 12:37:01,811 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1405892889_0001
   [druid] 2018-12-05 12:37:01,948 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 12:37:01,949 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1405892889_0001
   [druid] 2018-12-05 12:37:01,950 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 12:37:01,954 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:37:01,954 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 12:37:01,959 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 12:37:01,989 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 12:37:01,990 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1405892889_0001_m_000000_0
   [druid] 2018-12-05 12:37:02,007 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:37:02,011 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:37:02,079 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5f2d6f66
   [druid] 2018-12-05 12:37:02,086 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-05 12:37:02,132 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 12:37:02,132 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 12:37:02,132 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 12:37:02,132 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 12:37:02,132 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 12:37:02,135 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 12:37:02,536 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,536 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,537 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,537 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,537 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,537 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,537 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,537 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,537 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,537 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,538 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,538 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,538 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,538 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 12:37:02,951 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1405892889_0001 running in uber mode : false
   [druid] 2018-12-05 12:37:02,952 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 12:37:03,373 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 12:37:03,374 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 12:37:03,374 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 12:37:03,374 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 400; bufvoid = 104857600
   [druid] 2018-12-05 12:37:03,374 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
   [druid] 2018-12-05 12:37:03,384 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 12:37:03,390 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1405892889_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:37:03,398 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 12:37:03,398 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1405892889_0001_m_000000_0' done.
   [druid] 2018-12-05 12:37:03,398 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1405892889_0001_m_000000_0
   [druid] 2018-12-05 12:37:03,398 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 12:37:03,400 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 12:37:03,400 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1405892889_0001_r_000000_0
   [druid] 2018-12-05 12:37:03,406 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 12:37:03,406 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 12:37:03,483 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5c472810
   [druid] 2018-12-05 12:37:03,486 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4d0471bf
   [druid] 2018-12-05 12:37:03,497 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 12:37:03,499 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1405892889_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 12:37:03,524 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1405892889_0001_m_000000_0 decomp: 410 len: 414 to MEMORY
   [druid] 2018-12-05 12:37:03,527 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 410 bytes from map-output for attempt_local1405892889_0001_m_000000_0
   [druid] 2018-12-05 12:37:03,528 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 410, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->410
   [druid] 2018-12-05 12:37:03,530 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 12:37:03,530 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:37:03,530 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 12:37:03,539 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:37:03,539 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 334 bytes
   [druid] 2018-12-05 12:37:03,541 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 410 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 12:37:03,542 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 414 bytes from disk
   [druid] 2018-12-05 12:37:03,542 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 12:37:03,542 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 12:37:03,543 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 334 bytes
   [druid] 2018-12-05 12:37:03,543 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 12:37:03,558 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 12:37:03,654 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1405892889_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 12:37:03,655 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 12:37:03,655 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1405892889_0001_r_000000_0' done.
   [druid] 2018-12-05 12:37:03,655 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1405892889_0001_r_000000_0
   [druid] 2018-12-05 12:37:03,655 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 12:37:03,662 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 12:37:03,955 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 12:37:03,955 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1405892889_0001 completed successfully
   [druid] 2018-12-05 12:37:03,966 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1178
		FILE: Number of bytes written=604492
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=65
		Map output records=4
		Map output bytes=400
		Map output materialized bytes=414
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=414
		Reduce input records=4
		Reduce output records=3
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=636485632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27156
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 14:51:08,298 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 14:51:08,300 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 14:51:09,018 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 14:51:09,098 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 14:51:09,128 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 14:51:09,199 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local571091734_0001
   [druid] 2018-12-05 14:51:09,317 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 14:51:09,317 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local571091734_0001
   [druid] 2018-12-05 14:51:09,319 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 14:51:09,324 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 14:51:09,324 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 14:51:09,329 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 14:51:09,363 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 14:51:09,364 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local571091734_0001_m_000000_0
   [druid] 2018-12-05 14:51:09,382 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 14:51:09,386 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 14:51:09,580 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@513ac1d3
   [druid] 2018-12-05 14:51:09,586 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-05 14:51:09,631 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 14:51:09,632 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 14:51:09,632 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 14:51:09,632 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 14:51:09,632 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 14:51:09,635 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 14:51:10,063 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,064 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,064 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,064 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,064 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,064 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,064 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,064 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,065 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,065 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,065 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,065 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,065 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,066 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 14:51:10,319 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local571091734_0001 running in uber mode : false
   [druid] 2018-12-05 14:51:10,321 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 14:51:10,875 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 14:51:10,876 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 14:51:10,877 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 14:51:10,877 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 400; bufvoid = 104857600
   [druid] 2018-12-05 14:51:10,877 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
   [druid] 2018-12-05 14:51:10,981 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 14:51:10,987 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local571091734_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 14:51:10,994 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 14:51:10,994 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local571091734_0001_m_000000_0' done.
   [druid] 2018-12-05 14:51:10,994 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local571091734_0001_m_000000_0
   [druid] 2018-12-05 14:51:10,994 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 14:51:10,996 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 14:51:10,996 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local571091734_0001_r_000000_0
   [druid] 2018-12-05 14:51:11,002 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 14:51:11,002 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 14:51:11,083 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1d576b5c
   [druid] 2018-12-05 14:51:11,087 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3b49fa0e
   [druid] 2018-12-05 14:51:11,101 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 14:51:11,103 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local571091734_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 14:51:11,136 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local571091734_0001_m_000000_0 decomp: 410 len: 414 to MEMORY
   [druid] 2018-12-05 14:51:11,142 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 410 bytes from map-output for attempt_local571091734_0001_m_000000_0
   [druid] 2018-12-05 14:51:11,144 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 410, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->410
   [druid] 2018-12-05 14:51:11,152 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 14:51:11,153 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 14:51:11,153 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 14:51:11,164 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 14:51:11,164 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 334 bytes
   [druid] 2018-12-05 14:51:11,166 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 410 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 14:51:11,167 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 414 bytes from disk
   [druid] 2018-12-05 14:51:11,167 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 14:51:11,168 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 14:51:11,169 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 334 bytes
   [druid] 2018-12-05 14:51:11,169 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 14:51:11,187 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 14:51:11,278 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local571091734_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 14:51:11,279 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 14:51:11,279 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local571091734_0001_r_000000_0' done.
   [druid] 2018-12-05 14:51:11,279 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local571091734_0001_r_000000_0
   [druid] 2018-12-05 14:51:11,279 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 14:51:11,284 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 14:51:11,325 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 14:51:11,325 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local571091734_0001 completed successfully
   [druid] 2018-12-05 14:51:11,337 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=1178
		FILE: Number of bytes written=601412
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=65
		Map output records=4
		Map output bytes=400
		Map output materialized bytes=414
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=414
		Reduce input records=4
		Reduce output records=3
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=633339904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27156
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 15:00:31,058 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:00:31,060 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:00:31,609 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 15:00:31,678 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:00:31,708 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 15:00:31,775 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1390899458_0001
   [druid] 2018-12-05 15:00:31,892 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 15:00:31,893 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1390899458_0001
   [druid] 2018-12-05 15:00:31,894 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:00:31,899 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 15:00:31,899 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:00:31,905 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 15:00:31,935 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:00:31,937 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1390899458_0001_m_000000_0
   [druid] 2018-12-05 15:00:31,956 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 15:00:31,959 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 15:00:32,031 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2cde39ac
   [druid] 2018-12-05 15:00:32,037 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/05/30/part-m-00000:0+27156
   [druid] 2018-12-05 15:00:32,084 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 15:00:32,084 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 15:00:32,084 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 15:00:32,084 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 15:00:32,084 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 15:00:32,087 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:00:32,498 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,499 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,499 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,499 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,499 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,499 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,499 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,499 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,500 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,500 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,500 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,500 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,501 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,501 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:00:32,894 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1390899458_0001 running in uber mode : false
   [druid] 2018-12-05 15:00:32,898 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 15:00:33,274 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 15:00:33,275 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:00:33,393 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1390899458_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 15:00:33,401 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 15:00:33,401 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1390899458_0001_m_000000_0' done.
   [druid] 2018-12-05 15:00:33,401 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1390899458_0001_m_000000_0
   [druid] 2018-12-05 15:00:33,401 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 15:00:33,403 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 15:00:33,403 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1390899458_0001_r_000000_0
   [druid] 2018-12-05 15:00:33,409 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 15:00:33,409 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 15:00:33,490 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1cc77e59
   [druid] 2018-12-05 15:00:33,493 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2eab9db2
   [druid] 2018-12-05 15:00:33,506 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 15:00:33,508 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1390899458_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 15:00:33,543 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1390899458_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2018-12-05 15:00:33,550 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1390899458_0001_m_000000_0
   [druid] 2018-12-05 15:00:33,552 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2018-12-05 15:00:33,553 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 15:00:33,554 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 15:00:33,554 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 15:00:33,565 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:00:33,566 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-05 15:00:33,568 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 15:00:33,568 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2018-12-05 15:00:33,569 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 15:00:33,569 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:00:33,571 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2018-12-05 15:00:33,572 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 15:00:33,591 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 15:00:33,596 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1390899458_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 15:00:33,597 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:00:33,597 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1390899458_0001_r_000000_0' done.
   [druid] 2018-12-05 15:00:33,597 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1390899458_0001_r_000000_0
   [druid] 2018-12-05 15:00:33,597 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 15:00:33,602 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 15:00:33,900 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:00:33,900 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1390899458_0001 completed successfully
   [druid] 2018-12-05 15:00:33,911 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=362
		FILE: Number of bytes written=603268
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=54312
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=65
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=635437056
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=27156
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 15:06:07,680 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 15:06:07,681 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 15:06:08,244 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 15:06:08,313 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 15:06:08,339 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 15:06:08,401 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1166071605_0001
   [druid] 2018-12-05 15:06:08,517 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 15:06:08,518 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1166071605_0001
   [druid] 2018-12-05 15:06:08,519 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 15:06:08,522 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 15:06:08,523 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 15:06:08,526 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 15:06:08,553 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 15:06:08,554 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1166071605_0001_m_000000_0
   [druid] 2018-12-05 15:06:08,572 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 15:06:08,575 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 15:06:08,648 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@705d0ab2
   [druid] 2018-12-05 15:06:08,654 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 15:06:08,701 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 15:06:08,701 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 15:06:08,701 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 15:06:08,701 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 15:06:08,701 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 15:06:08,704 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 15:06:09,118 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:06:09,119 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:06:09,119 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:06:09,119 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:06:09,119 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:06:09,120 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:06:09,120 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:06:09,120 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:06:09,120 [ask Executor #0] INFO  duce.NewMember.NewMemberMapper {1} - serverTime或者member不能为空
   [druid] 2018-12-05 15:06:09,520 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1166071605_0001 running in uber mode : false
   [druid] 2018-12-05 15:06:09,522 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 15:06:14,629 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 15:06:15,526 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 28% reduce 0%
   [druid] 2018-12-05 15:06:17,631 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 15:06:18,527 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 45% reduce 0%
   [druid] 2018-12-05 15:06:20,632 [nication thread] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 15:06:21,528 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 62% reduce 0%
   [druid] 2018-12-05 15:06:21,595 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map > map
   [druid] 2018-12-05 15:06:21,597 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 15:06:21,597 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 15:06:21,597 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 1006; bufvoid = 104857600
   [druid] 2018-12-05 15:06:21,597 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
   [druid] 2018-12-05 15:06:21,632 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 15:06:21,638 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1166071605_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 15:06:21,639 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 15:06:21,639 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1166071605_0001_m_000000_0' done.
   [druid] 2018-12-05 15:06:21,639 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1166071605_0001_m_000000_0
   [druid] 2018-12-05 15:06:21,639 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 15:06:21,642 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 15:06:21,642 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1166071605_0001_r_000000_0
   [druid] 2018-12-05 15:06:21,649 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 15:06:21,649 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 15:06:21,741 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1f45c101
   [druid] 2018-12-05 15:06:21,746 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1ab08465
   [druid] 2018-12-05 15:06:21,762 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 15:06:21,764 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1166071605_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 15:06:21,796 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1166071605_0001_m_000000_0 decomp: 1024 len: 1028 to MEMORY
   [druid] 2018-12-05 15:06:21,801 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 1024 bytes from map-output for attempt_local1166071605_0001_m_000000_0
   [druid] 2018-12-05 15:06:21,803 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 1024, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1024
   [druid] 2018-12-05 15:06:21,804 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 15:06:21,804 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 15:06:21,805 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 15:06:21,815 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:06:21,815 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 944 bytes
   [druid] 2018-12-05 15:06:21,816 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 1024 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 15:06:21,817 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 1028 bytes from disk
   [druid] 2018-12-05 15:06:21,817 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 15:06:21,817 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 15:06:21,818 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 944 bytes
   [druid] 2018-12-05 15:06:21,818 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 15:06:21,833 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 15:06:21,919 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1166071605_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 15:06:21,920 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 15:06:21,920 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1166071605_0001_r_000000_0' done.
   [druid] 2018-12-05 15:06:21,920 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1166071605_0001_r_000000_0
   [druid] 2018-12-05 15:06:21,920 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 15:06:21,925 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 15:06:22,528 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 15:06:22,528 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1166071605_0001 completed successfully
   [druid] 2018-12-05 15:06:22,541 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=2408
		FILE: Number of bytes written=606336
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=8
		Map output bytes=1006
		Map output materialized bytes=1028
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=1028
		Reduce input records=8
		Reduce output records=3
		Spilled Records=16
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=122
		Total committed heap usage (bytes)=787480576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 16:33:53,966 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:33:53,967 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:33:54,624 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 16:33:54,698 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:33:54,724 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 16:33:54,799 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1022668707_0001
   [druid] 2018-12-05 16:33:54,933 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 16:33:54,934 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1022668707_0001
   [druid] 2018-12-05 16:33:54,935 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:33:54,940 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:33:54,940 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:33:54,945 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 16:33:54,974 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:33:54,975 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1022668707_0001_m_000000_0
   [druid] 2018-12-05 16:33:54,996 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:33:55,001 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 16:33:55,203 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7e0daf6e
   [druid] 2018-12-05 16:33:55,212 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 16:33:55,262 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 16:33:55,262 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 16:33:55,262 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 16:33:55,263 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 16:33:55,263 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 16:33:55,266 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:33:55,767 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:33:55,767 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:33:55,767 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:33:55,767 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:33:55,768 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:33:55,768 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:33:55,768 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:33:55,768 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:33:55,768 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:33:55,881 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:33:55,883 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:33:55,883 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 16:33:55,883 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 404578; bufvoid = 104857600
   [druid] 2018-12-05 16:33:55,883 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26201752(104807008); length = 12645/6553600
   [druid] 2018-12-05 16:33:55,925 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:33:55,932 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1022668707_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 16:33:55,937 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1022668707_0001 running in uber mode : false
   [druid] 2018-12-05 16:33:55,938 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2018-12-05 16:33:55,939 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 16:33:55,939 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1022668707_0001_m_000000_0' done.
   [druid] 2018-12-05 16:33:55,939 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1022668707_0001_m_000000_0
   [druid] 2018-12-05 16:33:55,939 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 16:33:55,941 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 16:33:55,941 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1022668707_0001_r_000000_0
   [druid] 2018-12-05 16:33:55,946 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:33:55,946 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 16:33:56,017 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@37ca4fc
   [druid] 2018-12-05 16:33:56,019 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@33b86992
   [druid] 2018-12-05 16:33:56,032 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 16:33:56,034 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1022668707_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 16:33:56,061 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1022668707_0001_m_000000_0 decomp: 410904 len: 410908 to MEMORY
   [druid] 2018-12-05 16:33:56,067 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 410904 bytes from map-output for attempt_local1022668707_0001_m_000000_0
   [druid] 2018-12-05 16:33:56,068 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 410904, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->410904
   [druid] 2018-12-05 16:33:56,069 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 16:33:56,070 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 16:33:56,070 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 16:33:56,080 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:33:56,081 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 410834 bytes
   [druid] 2018-12-05 16:33:56,089 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 410904 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 16:33:56,090 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 410908 bytes from disk
   [druid] 2018-12-05 16:33:56,091 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 16:33:56,091 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:33:56,092 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 410834 bytes
   [druid] 2018-12-05 16:33:56,092 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 16:33:56,342 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 16:33:56,654 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1022668707_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 16:33:56,655 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:33:56,655 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1022668707_0001_r_000000_0' done.
   [druid] 2018-12-05 16:33:56,655 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1022668707_0001_r_000000_0
   [druid] 2018-12-05 16:33:56,655 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 16:33:56,660 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 16:33:56,939 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:33:56,939 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1022668707_0001 completed successfully
   [druid] 2018-12-05 16:33:56,950 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=822168
		FILE: Number of bytes written=1836068
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=3162
		Map output bytes=404578
		Map output materialized bytes=410908
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=410908
		Reduce input records=3162
		Reduce output records=14
		Spilled Records=6324
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=2
		Total committed heap usage (bytes)=575668224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 16:35:13,371 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:35:13,372 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:35:13,988 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 16:35:14,056 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:35:14,083 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 16:35:14,144 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1231842118_0001
   [druid] 2018-12-05 16:35:14,271 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 16:35:14,272 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1231842118_0001
   [druid] 2018-12-05 16:35:14,273 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:35:14,277 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:35:14,277 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:35:14,282 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 16:35:14,313 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:35:14,315 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1231842118_0001_m_000000_0
   [druid] 2018-12-05 16:35:14,334 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:35:14,338 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 16:35:14,405 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@221e5249
   [druid] 2018-12-05 16:35:14,412 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 16:35:14,458 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 16:35:14,458 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 16:35:14,458 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 16:35:14,458 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 16:35:14,458 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 16:35:14,461 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:35:14,879 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:14,880 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:14,880 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:14,880 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:14,880 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:14,880 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:14,881 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:14,881 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:14,881 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:15,001 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:35:15,002 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:35:15,003 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 16:35:15,003 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 404578; bufvoid = 104857600
   [druid] 2018-12-05 16:35:15,003 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26201752(104807008); length = 12645/6553600
   [druid] 2018-12-05 16:35:15,055 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:35:15,062 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1231842118_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 16:35:15,070 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 16:35:15,070 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1231842118_0001_m_000000_0' done.
   [druid] 2018-12-05 16:35:15,070 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1231842118_0001_m_000000_0
   [druid] 2018-12-05 16:35:15,070 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 16:35:15,071 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 16:35:15,072 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1231842118_0001_r_000000_0
   [druid] 2018-12-05 16:35:15,076 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:35:15,077 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 16:35:15,155 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@e06f76c
   [druid] 2018-12-05 16:35:15,157 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@41770338
   [druid] 2018-12-05 16:35:15,168 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 16:35:15,170 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1231842118_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 16:35:15,199 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1231842118_0001_m_000000_0 decomp: 410904 len: 410908 to MEMORY
   [druid] 2018-12-05 16:35:15,204 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 410904 bytes from map-output for attempt_local1231842118_0001_m_000000_0
   [druid] 2018-12-05 16:35:15,205 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 410904, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->410904
   [druid] 2018-12-05 16:35:15,206 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 16:35:15,207 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 16:35:15,207 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 16:35:15,216 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:35:15,216 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 410834 bytes
   [druid] 2018-12-05 16:35:15,225 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 410904 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 16:35:15,226 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 410908 bytes from disk
   [druid] 2018-12-05 16:35:15,227 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 16:35:15,227 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:35:15,228 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 410834 bytes
   [druid] 2018-12-05 16:35:15,228 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 16:35:15,274 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1231842118_0001 running in uber mode : false
   [druid] 2018-12-05 16:35:15,275 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-12-05 16:35:15,469 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 16:35:15,810 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1231842118_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 16:35:15,810 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:35:15,810 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1231842118_0001_r_000000_0' done.
   [druid] 2018-12-05 16:35:15,810 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1231842118_0001_r_000000_0
   [druid] 2018-12-05 16:35:15,810 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 16:35:15,816 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 16:35:16,276 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:35:16,276 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1231842118_0001 completed successfully
   [druid] 2018-12-05 16:35:16,288 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=822168
		FILE: Number of bytes written=1836068
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=3162
		Map output bytes=404578
		Map output materialized bytes=410908
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=410908
		Reduce input records=3162
		Reduce output records=14
		Spilled Records=6324
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=631242752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 16:35:56,937 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:35:56,938 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:35:57,513 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 16:35:57,585 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:35:57,612 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 16:35:57,680 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local327189600_0001
   [druid] 2018-12-05 16:35:57,804 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 16:35:57,804 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local327189600_0001
   [druid] 2018-12-05 16:35:57,805 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:35:57,811 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:35:57,811 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:35:57,815 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 16:35:57,843 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:35:57,845 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local327189600_0001_m_000000_0
   [druid] 2018-12-05 16:35:57,864 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:35:57,868 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 16:35:57,938 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@795c5eab
   [druid] 2018-12-05 16:35:57,945 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 16:35:57,990 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 16:35:57,990 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 16:35:57,990 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 16:35:57,990 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 16:35:57,990 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 16:35:57,993 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:35:58,424 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:58,424 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:58,424 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:58,425 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:58,425 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:58,425 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:58,426 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:58,426 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:58,426 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:35:58,555 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:35:58,557 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:35:58,557 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 16:35:58,557 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 404578; bufvoid = 104857600
   [druid] 2018-12-05 16:35:58,557 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26201752(104807008); length = 12645/6553600
   [druid] 2018-12-05 16:35:58,603 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:35:58,624 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local327189600_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 16:35:58,632 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 16:35:58,632 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local327189600_0001_m_000000_0' done.
   [druid] 2018-12-05 16:35:58,633 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local327189600_0001_m_000000_0
   [druid] 2018-12-05 16:35:58,633 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 16:35:58,635 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 16:35:58,635 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local327189600_0001_r_000000_0
   [druid] 2018-12-05 16:35:58,640 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:35:58,640 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 16:35:58,716 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@15be8f15
   [druid] 2018-12-05 16:35:58,720 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6aae0625
   [druid] 2018-12-05 16:35:58,731 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 16:35:58,734 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local327189600_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 16:35:58,767 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local327189600_0001_m_000000_0 decomp: 410904 len: 410908 to MEMORY
   [druid] 2018-12-05 16:35:58,771 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 410904 bytes from map-output for attempt_local327189600_0001_m_000000_0
   [druid] 2018-12-05 16:35:58,772 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 410904, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->410904
   [druid] 2018-12-05 16:35:58,773 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 16:35:58,774 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 16:35:58,774 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 16:35:58,784 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:35:58,784 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 410834 bytes
   [druid] 2018-12-05 16:35:58,794 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 410904 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 16:35:58,795 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 410908 bytes from disk
   [druid] 2018-12-05 16:35:58,796 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 16:35:58,796 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:35:58,797 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 410834 bytes
   [druid] 2018-12-05 16:35:58,798 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 16:35:58,806 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local327189600_0001 running in uber mode : false
   [druid] 2018-12-05 16:35:58,807 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-12-05 16:35:59,045 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 16:35:59,339 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local327189600_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 16:35:59,340 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:35:59,340 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local327189600_0001_r_000000_0' done.
   [druid] 2018-12-05 16:35:59,340 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local327189600_0001_r_000000_0
   [druid] 2018-12-05 16:35:59,340 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 16:35:59,347 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 16:35:59,807 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:35:59,807 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local327189600_0001 completed successfully
   [druid] 2018-12-05 16:35:59,819 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=822168
		FILE: Number of bytes written=1832988
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=3162
		Map output bytes=404578
		Map output materialized bytes=410908
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=410908
		Reduce input records=3162
		Reduce output records=14
		Spilled Records=6324
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=631242752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 16:56:07,433 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:56:07,435 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:56:08,105 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 16:56:08,179 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:56:08,207 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 16:56:08,271 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local107920385_0001
   [druid] 2018-12-05 16:56:08,398 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 16:56:08,400 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local107920385_0001
   [druid] 2018-12-05 16:56:08,401 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:56:08,405 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:56:08,406 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:56:08,412 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 16:56:08,439 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:56:08,440 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local107920385_0001_m_000000_0
   [druid] 2018-12-05 16:56:08,463 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:56:08,468 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 16:56:08,542 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@513ac1d3
   [druid] 2018-12-05 16:56:08,549 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 16:56:08,593 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 16:56:08,594 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 16:56:08,594 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 16:56:08,594 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 16:56:08,594 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 16:56:08,597 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:56:09,014 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:56:09,015 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:56:09,015 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:56:09,015 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:56:09,016 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:56:09,016 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:56:09,016 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:56:09,016 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:56:09,017 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:56:09,127 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:56:09,129 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:56:09,130 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 16:56:09,130 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 404578; bufvoid = 104857600
   [druid] 2018-12-05 16:56:09,130 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26201752(104807008); length = 12645/6553600
   [druid] 2018-12-05 16:56:09,207 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:56:09,213 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local107920385_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 16:56:09,222 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 16:56:09,222 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local107920385_0001_m_000000_0' done.
   [druid] 2018-12-05 16:56:09,223 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local107920385_0001_m_000000_0
   [druid] 2018-12-05 16:56:09,223 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 16:56:09,224 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 16:56:09,225 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local107920385_0001_r_000000_0
   [druid] 2018-12-05 16:56:09,230 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:56:09,230 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 16:56:09,311 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@19e53092
   [druid] 2018-12-05 16:56:09,314 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2ad43e3e
   [druid] 2018-12-05 16:56:09,327 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 16:56:09,329 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local107920385_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 16:56:09,357 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local107920385_0001_m_000000_0 decomp: 410904 len: 410908 to MEMORY
   [druid] 2018-12-05 16:56:09,361 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 410904 bytes from map-output for attempt_local107920385_0001_m_000000_0
   [druid] 2018-12-05 16:56:09,362 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 410904, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->410904
   [druid] 2018-12-05 16:56:09,363 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 16:56:09,364 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 16:56:09,364 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 16:56:09,373 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:56:09,373 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 410834 bytes
   [druid] 2018-12-05 16:56:09,381 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 410904 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 16:56:09,382 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 410908 bytes from disk
   [druid] 2018-12-05 16:56:09,383 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 16:56:09,383 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:56:09,384 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 410834 bytes
   [druid] 2018-12-05 16:56:09,384 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 16:56:09,401 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local107920385_0001 running in uber mode : false
   [druid] 2018-12-05 16:56:09,402 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-12-05 16:56:09,642 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 16:56:09,910 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local107920385_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 16:56:09,911 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:56:09,911 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local107920385_0001_r_000000_0' done.
   [druid] 2018-12-05 16:56:09,911 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local107920385_0001_r_000000_0
   [druid] 2018-12-05 16:56:09,911 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 16:56:09,917 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 16:56:10,404 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:56:10,404 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local107920385_0001 completed successfully
   [druid] 2018-12-05 16:56:10,415 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=822168
		FILE: Number of bytes written=1832988
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=3162
		Map output bytes=404578
		Map output materialized bytes=410908
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=410908
		Reduce input records=3162
		Reduce output records=14
		Spilled Records=6324
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=3
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   [druid] 2018-12-05 16:57:15,548 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2018-12-05 16:57:15,549 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2018-12-05 16:57:16,130 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2018-12-05 16:57:16,198 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2018-12-05 16:57:16,227 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2018-12-05 16:57:16,293 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1392644467_0001
   [druid] 2018-12-05 16:57:16,427 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2018-12-05 16:57:16,427 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1392644467_0001
   [druid] 2018-12-05 16:57:16,428 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2018-12-05 16:57:16,433 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:57:16,433 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2018-12-05 16:57:16,439 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in setupJob()
   [druid] 2018-12-05 16:57:16,467 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2018-12-05 16:57:16,469 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1392644467_0001_m_000000_0
   [druid] 2018-12-05 16:57:16,492 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:57:16,496 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 16:57:16,570 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@159ccee1
   [druid] 2018-12-05 16:57:16,577 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: hdfs://Murphy:8020/ods/11/11/part-m-00000:0+784323
   [druid] 2018-12-05 16:57:16,625 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2018-12-05 16:57:16,625 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2018-12-05 16:57:16,625 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2018-12-05 16:57:16,625 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2018-12-05 16:57:16,625 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2018-12-05 16:57:16,628 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2018-12-05 16:57:17,056 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:57:17,056 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:57:17,057 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:57:17,057 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:57:17,057 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:57:17,057 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:57:17,058 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:57:17,058 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:57:17,058 [ask Executor #0] INFO  .SessionAnalysis.SessionMapper {1} - serverTime或者u_sd不能为空
   [druid] 2018-12-05 16:57:17,173 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2018-12-05 16:57:17,175 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2018-12-05 16:57:17,175 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2018-12-05 16:57:17,175 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 404578; bufvoid = 104857600
   [druid] 2018-12-05 16:57:17,175 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26201752(104807008); length = 12645/6553600
   [druid] 2018-12-05 16:57:17,239 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2018-12-05 16:57:17,246 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1392644467_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 16:57:17,254 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2018-12-05 16:57:17,254 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1392644467_0001_m_000000_0' done.
   [druid] 2018-12-05 16:57:17,254 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1392644467_0001_m_000000_0
   [druid] 2018-12-05 16:57:17,254 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2018-12-05 16:57:17,256 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2018-12-05 16:57:17,257 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1392644467_0001_r_000000_0
   [druid] 2018-12-05 16:57:17,262 [pool-6-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2018-12-05 16:57:17,263 [pool-6-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2018-12-05 16:57:17,345 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6ea9c59c
   [druid] 2018-12-05 16:57:17,348 [pool-6-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@433935cf
   [druid] 2018-12-05 16:57:17,361 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2018-12-05 16:57:17,363 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1392644467_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2018-12-05 16:57:17,392 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1392644467_0001_m_000000_0 decomp: 410904 len: 410908 to MEMORY
   [druid] 2018-12-05 16:57:17,396 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 410904 bytes from map-output for attempt_local1392644467_0001_m_000000_0
   [druid] 2018-12-05 16:57:17,398 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 410904, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->410904
   [druid] 2018-12-05 16:57:17,399 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2018-12-05 16:57:17,399 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 16:57:17,400 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2018-12-05 16:57:17,429 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1392644467_0001 running in uber mode : false
   [druid] 2018-12-05 16:57:17,430 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2018-12-05 16:57:17,437 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:57:17,437 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 410834 bytes
   [druid] 2018-12-05 16:57:17,445 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 410904 bytes to disk to satisfy reduce memory limit
   [druid] 2018-12-05 16:57:17,446 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 410908 bytes from disk
   [druid] 2018-12-05 16:57:17,447 [pool-6-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2018-12-05 16:57:17,447 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2018-12-05 16:57:17,448 [pool-6-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 410834 bytes
   [druid] 2018-12-05 16:57:17,448 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2018-12-05 16:57:17,726 [pool-6-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2018-12-05 16:57:18,052 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1392644467_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2018-12-05 16:57:18,053 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2018-12-05 16:57:18,053 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1392644467_0001_r_000000_0' done.
   [druid] 2018-12-05 16:57:18,053 [pool-6-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1392644467_0001_r_000000_0
   [druid] 2018-12-05 16:57:18,053 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2018-12-05 16:57:18,058 [Thread-3       ] WARN  lib.output.FileOutputCommitter {1} - Output Path is null in commitJob()
   [druid] 2018-12-05 16:57:18,431 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2018-12-05 16:57:18,431 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1392644467_0001 completed successfully
   [druid] 2018-12-05 16:57:18,442 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 35
	File System Counters
		FILE: Number of bytes read=822168
		FILE: Number of bytes written=1836068
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1568646
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Map-Reduce Framework
		Map input records=1590
		Map output records=3162
		Map output bytes=404578
		Map output materialized bytes=410908
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=410908
		Reduce input records=3162
		Reduce output records=14
		Spilled Records=6324
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=632291328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=784323
	File Output Format Counters 
		Bytes Written=0
   